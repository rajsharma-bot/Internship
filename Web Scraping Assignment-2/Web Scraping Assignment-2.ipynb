{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30a0cafa",
   "metadata": {},
   "source": [
    "# WEB SCRAPING – ASSIGNMENT 2\n",
    "\n",
    "using selenium in Jupyter NoteBook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4587f460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.select import Select\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873e2c50",
   "metadata": {},
   "source": [
    "# Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. \n",
    "You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "482c4cff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job-title</th>\n",
       "      <th>job-location</th>\n",
       "      <th>company_name</th>\n",
       "      <th>experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Optum</td>\n",
       "      <td>5-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Leap COE Intern(Data Analyst)</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Info Origin Inc.</td>\n",
       "      <td>0-1 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst - Data Science, 3 To 5 Years</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai (All Areas)</td>\n",
       "      <td>Rise Finconnect</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst, plsql, Tableau, Informatica</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Hyderabad/Secunder...</td>\n",
       "      <td>Capgemini</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst / MIS</td>\n",
       "      <td>Bangalore/Bengaluru(Indira Nagar)</td>\n",
       "      <td>Trukker Technologies</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Data Analyst - SQL/Tableau</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Global Employees</td>\n",
       "      <td>7-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Analyst II</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst - Data Visualization &amp; Reporting</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...</td>\n",
       "      <td>Global Employees</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Remote</td>\n",
       "      <td>LINGARO INDIA PRIVATE LIMITED</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst - EdTech</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>TalentStack</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      job-title   \\\n",
       "0                            Senior Data Analyst   \n",
       "1                  Leap COE Intern(Data Analyst)   \n",
       "2      Data Analyst - Data Science, 3 To 5 Years   \n",
       "3      Data Analyst, plsql, Tableau, Informatica   \n",
       "4                             Data Analyst / MIS   \n",
       "5              Senior Data Analyst - SQL/Tableau   \n",
       "6                         Senior Data Analyst II   \n",
       "7  Data Analyst - Data Visualization & Reporting   \n",
       "8                                   Data Analyst   \n",
       "9                          Data Analyst - EdTech   \n",
       "\n",
       "                                        job-location  \\\n",
       "0                                Bangalore/Bengaluru   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2            Bangalore/Bengaluru, Mumbai (All Areas)   \n",
       "3  Bangalore/Bengaluru, Noida, Hyderabad/Secunder...   \n",
       "4                  Bangalore/Bengaluru(Indira Nagar)   \n",
       "5  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7  Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...   \n",
       "8                                             Remote   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                    company_name experience_required  \n",
       "0                          Optum             5-7 Yrs  \n",
       "1               Info Origin Inc.             0-1 Yrs  \n",
       "2                Rise Finconnect             2-6 Yrs  \n",
       "3                      Capgemini             3-8 Yrs  \n",
       "4           Trukker Technologies             3-6 Yrs  \n",
       "5               Global Employees            7-12 Yrs  \n",
       "6                       Flipkart             3-6 Yrs  \n",
       "7               Global Employees            5-10 Yrs  \n",
       "8  LINGARO INDIA PRIVATE LIMITED             3-5 Yrs  \n",
       "9                    TalentStack             2-6 Yrs  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")  \n",
    "driver.maximize_window()\n",
    "driver.get(\"https://www.naukri.com/\")\n",
    "\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys(\"Data Analyst\")\n",
    "\n",
    "location=driver.find_element(By.XPATH,'//input[@placeholder=\"Enter location\"]')\n",
    "location.send_keys('Bangalore')\n",
    "\n",
    "search=driver.find_element(By.XPATH,'//div[@class=\"qsbSubmit\"]')\n",
    "search.click()\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "job_company=[]\n",
    "job_experience=[]\n",
    "\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "\n",
    "\n",
    "location_tags=driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "\n",
    "company_tags=driver.find_elements(By.XPATH,\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in company_tags[0:10]:\n",
    "    cname=i.text\n",
    "    job_company.append(cname)\n",
    "\n",
    "\n",
    "experience_tags=driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi experience']//span\")\n",
    "for i  in experience_tags[0:10]:\n",
    "    experience=i.text\n",
    "    job_experience.append(experience)\n",
    "\n",
    "driver.close()\n",
    "\n",
    "dataAnalyst=pd.DataFrame({'job-title ':job_title,'job-location':job_location,'company_name':job_company,'experience_required':job_experience})\n",
    "dataAnalyst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30e0e9c",
   "metadata": {},
   "source": [
    "# Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16ef0f08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job-title</th>\n",
       "      <th>job-location</th>\n",
       "      <th>company_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Analystics &amp; Modeling Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Job||Job Opening For AI Technologist - Data Sc...</td>\n",
       "      <td>Bangalore/Bengaluru, New Delhi, Hyderabad/Secu...</td>\n",
       "      <td>Wipro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Assistant Manager - Data Science</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Pune</td>\n",
       "      <td>CitiusTech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data scientist _Tata Consultancy Services(Tcs)</td>\n",
       "      <td>Bangalore/Bengaluru, Kochi/Cochin, Indore, New...</td>\n",
       "      <td>TATA CONSULTANCY SERVICES (TCS)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Science Senior Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hiring For DATA Scientist @ NTT DATA Business ...</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Hyderabad/Secunder...</td>\n",
       "      <td>NTT DATA Business Solutions Private Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Expert Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai</td>\n",
       "      <td>United Phosphorus Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Urgent Job Opening For AI Practitioner - Data ...</td>\n",
       "      <td>Bangalore/Bengaluru, Kochi/Cochin, New Delhi, ...</td>\n",
       "      <td>Wipro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist - Full Stack</td>\n",
       "      <td>Bangalore/Bengaluru, Hyderabad/Secunderabad</td>\n",
       "      <td>Salesforce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BCAI - Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Bosch Global Software Technologies</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          job-title   \\\n",
       "0                   Analystics & Modeling Specialist   \n",
       "1  Job||Job Opening For AI Technologist - Data Sc...   \n",
       "2                   Assistant Manager - Data Science   \n",
       "3     Data scientist _Tata Consultancy Services(Tcs)   \n",
       "4                        Data Science Senior Analyst   \n",
       "5  Hiring For DATA Scientist @ NTT DATA Business ...   \n",
       "6                              Expert Data Scientist   \n",
       "7  Urgent Job Opening For AI Practitioner - Data ...   \n",
       "8                        Data Scientist - Full Stack   \n",
       "9                       BCAI - Senior Data Scientist   \n",
       "\n",
       "                                        job-location  \\\n",
       "0  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...   \n",
       "1  Bangalore/Bengaluru, New Delhi, Hyderabad/Secu...   \n",
       "2                  Bangalore/Bengaluru, Mumbai, Pune   \n",
       "3  Bangalore/Bengaluru, Kochi/Cochin, Indore, New...   \n",
       "4  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...   \n",
       "5  Bangalore/Bengaluru, Noida, Hyderabad/Secunder...   \n",
       "6                        Bangalore/Bengaluru, Mumbai   \n",
       "7  Bangalore/Bengaluru, Kochi/Cochin, New Delhi, ...   \n",
       "8        Bangalore/Bengaluru, Hyderabad/Secunderabad   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                                  company_name  \n",
       "0                                    Accenture  \n",
       "1                                        Wipro  \n",
       "2                                   CitiusTech  \n",
       "3              TATA CONSULTANCY SERVICES (TCS)  \n",
       "4                                    Accenture  \n",
       "5  NTT DATA Business Solutions Private Limited  \n",
       "6                    United Phosphorus Limited  \n",
       "7                                        Wipro  \n",
       "8                                   Salesforce  \n",
       "9           Bosch Global Software Technologies  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")  \n",
    "driver.maximize_window()\n",
    "driver.get(\"https://www.naukri.com/\")\n",
    "\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys(\"Data Scientist\")\n",
    "\n",
    "location=driver.find_element(By.XPATH,'//input[@placeholder=\"Enter location\"]')\n",
    "location.send_keys('Bangalore')\n",
    "\n",
    "search=driver.find_element(By.XPATH,'//div[@class=\"qsbSubmit\"]')\n",
    "search.click()\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "job_company=[]\n",
    "job_experience=[]\n",
    "\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "\n",
    "\n",
    "location_tags=driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "\n",
    "company_tags=driver.find_elements(By.XPATH,\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in company_tags[0:10]:\n",
    "    cname=i.text\n",
    "    job_company.append(cname)\n",
    "\n",
    "driver.close()\n",
    "\n",
    "dataScientist=pd.DataFrame({'job-title ':job_title,'job-location':job_location,'company_name':job_company})\n",
    "dataScientist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fc1ef8",
   "metadata": {},
   "source": [
    "# Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "You have to use the location and salary filter\n",
    "\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "\n",
    "You have to scrape the job-title, job-location, company name, experience required.\n",
    "\n",
    "The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4576bec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job-title</th>\n",
       "      <th>job-location</th>\n",
       "      <th>company_name</th>\n",
       "      <th>experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data scientist _Tata Consultancy Services(Tcs)</td>\n",
       "      <td>Delhi / NCR, Kochi/Cochin, Indore, New Delhi, ...</td>\n",
       "      <td>TATA CONSULTANCY SERVICES (TCS)</td>\n",
       "      <td>9-14 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida, Ghaziabad, Gurgaon/Gurugram</td>\n",
       "      <td>Genpact</td>\n",
       "      <td>6-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hiring Of Data Science Intern</td>\n",
       "      <td>Noida, Bangalore/Bengaluru</td>\n",
       "      <td>FLIP ROBO TECHNOLOGIES PRIVATE LIMITED</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist For Healthcare Product team</td>\n",
       "      <td>Delhi / NCR, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>SECUREKLOUD TECHNOLOGIES</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist For Healthcare Product team</td>\n",
       "      <td>Delhi / NCR, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>SECUREKLOUD TECHNOLOGIES</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist Intern</td>\n",
       "      <td>Delhi / NCR, Noida, Faridabad, Gurgaon/Gurugram</td>\n",
       "      <td>Care Health Insurance (CHI)</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi / NCR, Pune, Bangalore/Bengaluru</td>\n",
       "      <td>Mount Talent Consulting Private Limited</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Knowledge/Data Scientist</td>\n",
       "      <td>Delhi / NCR</td>\n",
       "      <td>BOLD Technology Systems</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Delhi / NCR, Noida, Faridabad, Gurgaon/Gurugra...</td>\n",
       "      <td>Mount Talent Consulting Private Limited</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>PRASU SOFTWARE SOLUTIONS PRIVATE LIMITED</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       job-title   \\\n",
       "0  Data scientist _Tata Consultancy Services(Tcs)   \n",
       "1                                  Data Scientist   \n",
       "2                   Hiring Of Data Science Intern   \n",
       "3      Data Scientist For Healthcare Product team   \n",
       "4      Data Scientist For Healthcare Product team   \n",
       "5                           Data Scientist Intern   \n",
       "6                                  Data Scientist   \n",
       "7                        Knowledge/Data Scientist   \n",
       "8                                    Data Science   \n",
       "9                                  Data Scientist   \n",
       "\n",
       "                                        job-location  \\\n",
       "0  Delhi / NCR, Kochi/Cochin, Indore, New Delhi, ...   \n",
       "1                 Noida, Ghaziabad, Gurgaon/Gurugram   \n",
       "2                         Noida, Bangalore/Bengaluru   \n",
       "3          Delhi / NCR, Chennai, Bangalore/Bengaluru   \n",
       "4          Delhi / NCR, Chennai, Bangalore/Bengaluru   \n",
       "5    Delhi / NCR, Noida, Faridabad, Gurgaon/Gurugram   \n",
       "6             Delhi / NCR, Pune, Bangalore/Bengaluru   \n",
       "7                                        Delhi / NCR   \n",
       "8  Delhi / NCR, Noida, Faridabad, Gurgaon/Gurugra...   \n",
       "9                                   Gurgaon/Gurugram   \n",
       "\n",
       "                               company_name experience_required  \n",
       "0           TATA CONSULTANCY SERVICES (TCS)            9-14 Yrs  \n",
       "1                                   Genpact            6-10 Yrs  \n",
       "2    FLIP ROBO TECHNOLOGIES PRIVATE LIMITED             0-2 Yrs  \n",
       "3                  SECUREKLOUD TECHNOLOGIES             2-7 Yrs  \n",
       "4                  SECUREKLOUD TECHNOLOGIES             2-7 Yrs  \n",
       "5               Care Health Insurance (CHI)             0-0 Yrs  \n",
       "6   Mount Talent Consulting Private Limited             2-4 Yrs  \n",
       "7                   BOLD Technology Systems             3-6 Yrs  \n",
       "8   Mount Talent Consulting Private Limited             2-5 Yrs  \n",
       "9  PRASU SOFTWARE SOLUTIONS PRIVATE LIMITED             2-4 Yrs  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")  \n",
    "driver.maximize_window()\n",
    "driver.get(\"https://www.naukri.com/\")\n",
    "\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys(\"Data Scientist\")\n",
    "\n",
    "#location=driver.find_element(By.XPATH,'//input[@placeholder=\"Enter location\"]')\n",
    "#location.send_keys('Bangalore')\n",
    "search=driver.find_element(By.XPATH,'//div[@class=\"qsbSubmit\"]')\n",
    "search.click()\n",
    "time.sleep(3)\n",
    "driver.find_element(By.XPATH,\"//span[@title='Delhi / NCR']\").click()\n",
    "time.sleep(3)\n",
    "driver.find_element(By.XPATH,\"//span[@title='0-3 Lakhs']\").click()\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "job_company=[]\n",
    "job_experience=[]\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "\n",
    "\n",
    "location_tags=driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "\n",
    "company_tags=driver.find_elements(By.XPATH,\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in company_tags[0:10]:\n",
    "    cname=i.text\n",
    "    job_company.append(cname)\n",
    "\n",
    "\n",
    "experience_tags=driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi experience']//span\")\n",
    "for i  in experience_tags[0:10]:\n",
    "    experience=i.text\n",
    "    job_experience.append(experience)\n",
    "\n",
    "driver.close()\n",
    "\n",
    "data_ScientistLoc=pd.DataFrame({'job-title ':job_title,'job-location':job_location,'company_name':job_company,'experience_required':job_experience})\n",
    "data_ScientistLoc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d7864d",
   "metadata": {},
   "source": [
    "# Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "\n",
    "2. Product Description\n",
    "\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "46cb4418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>Polarized Retro Square Sunglasses (61)</td>\n",
       "      <td>₹699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart UV Protection, Polarized Aviator S...</td>\n",
       "      <td>₹949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DAHAAZIL</td>\n",
       "      <td>UV Protection, Night Vision, Riding Glasses Wa...</td>\n",
       "      <td>₹194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Aviator S...</td>\n",
       "      <td>₹949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>LIZA ANGEL</td>\n",
       "      <td>Riding Glasses, Night Vision Spectacle Sunglas...</td>\n",
       "      <td>₹179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>GANSTA</td>\n",
       "      <td>Gradient, UV Protection Aviator Sunglasses (57)</td>\n",
       "      <td>₹296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Shield Sunglasses (Free Size)</td>\n",
       "      <td>₹669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Aviator S...</td>\n",
       "      <td>₹1,415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Brand                                Product Description   Price\n",
       "0       ROYAL SON             Polarized Retro Square Sunglasses (61)    ₹699\n",
       "1   VINCENT CHASE  by Lenskart UV Protection, Polarized Aviator S...    ₹949\n",
       "2        DAHAAZIL  UV Protection, Night Vision, Riding Glasses Wa...    ₹194\n",
       "3        Fastrack      UV Protection Wayfarer Sunglasses (Free Size)    ₹599\n",
       "4        Fastrack      UV Protection Wayfarer Sunglasses (Free Size)    ₹359\n",
       "..            ...                                                ...     ...\n",
       "95  VINCENT CHASE  by Lenskart Polarized, UV Protection Aviator S...    ₹949\n",
       "96     LIZA ANGEL  Riding Glasses, Night Vision Spectacle Sunglas...    ₹179\n",
       "97         GANSTA    Gradient, UV Protection Aviator Sunglasses (57)    ₹296\n",
       "98       Fastrack        UV Protection Shield Sunglasses (Free Size)    ₹669\n",
       "99  VINCENT CHASE  by Lenskart Polarized, UV Protection Aviator S...  ₹1,415\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")  \n",
    "driver.maximize_window()\n",
    "driver.get(\"https://www.flipkart.com/\")\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "try:\n",
    "    driver.find_element(By.XPATH,'//button[@class=\"_2KpZ6l _2doB4z\"]').click()\n",
    "except NoSuchElementException:\n",
    "    print('No login pop-up')\n",
    "    \n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "driver.find_element(By.XPATH,'//input[@class=\"_3704LK\"]').send_keys('sunglasses')\n",
    "driver.find_element(By.XPATH,'//button[@class=\"L0Z3Pu\"]').click()\n",
    "\n",
    "brand=[]\n",
    "product_description=[]\n",
    "price=[]\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "for page in range(0,3):\n",
    "    brand_tags=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for i in brand_tags[0:100]:\n",
    "        brandName=i.text\n",
    "        brand.append(brandName)\n",
    "    \n",
    "    product_tags=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    for j in product_tags[0:100]:\n",
    "        productD=j.text\n",
    "        product_description.append(productD)\n",
    "        \n",
    "    price_tags=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    for k in price_tags[0:100]:\n",
    "        price_t=k.text\n",
    "        price.append(price_t)\n",
    "    \n",
    "time.sleep(3)\n",
    "next_page=driver.find_element(By.XPATH,'//a[@class=\"ge-49M\"]')\n",
    "next_page.click\n",
    "    \n",
    "driver.close()\n",
    "\n",
    "sunglasses_df=pd.DataFrame({'Brand':brand[0:100],'Product Description':product_description[0:100],'Price':price[0:100]})\n",
    "sunglasses_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f618c1d",
   "metadata": {},
   "source": [
    "# Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone.\n",
    "This task will be done in following steps:\n",
    "\n",
    "1. First get the webpage https://www.flipkart.com/\n",
    "\n",
    "2. Enter “iphone 11” in “Search” field .\n",
    "\n",
    "3. Then click the search button."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "92ebb943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review summary</th>\n",
       "      <th>Full review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>What a camera .....just awesome ..you can feel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.\\n\\nI’m am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>i11 is worthy to buy, too much happy with the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>It's my first time to use iOS phone and I am l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>4</td>\n",
       "      <td>Good choice</td>\n",
       "      <td>So far it’s been an AMAZING experience coming ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating       Review summary  \\\n",
       "0       5       Simply awesome   \n",
       "1       5     Perfect product!   \n",
       "2       5  Best in the market!   \n",
       "3       5   Highly recommended   \n",
       "4       5    Worth every penny   \n",
       "..    ...                  ...   \n",
       "95      5            Fabulous!   \n",
       "96      5        Great product   \n",
       "97      5    Worth every penny   \n",
       "98      5   Highly recommended   \n",
       "99      4          Good choice   \n",
       "\n",
       "                                          Full review  \n",
       "0   Really satisfied with the Product I received.....  \n",
       "1   Amazing phone with great cameras and better ba...  \n",
       "2   Great iPhone very snappy experience as apple k...  \n",
       "3   What a camera .....just awesome ..you can feel...  \n",
       "4   Previously I was using one plus 3t it was a gr...  \n",
       "..                                                ...  \n",
       "95  This is my first iOS phone. I am very happy wi...  \n",
       "96  Amazing Powerful and Durable Gadget.\\n\\nI’m am...  \n",
       "97  i11 is worthy to buy, too much happy with the ...  \n",
       "98  It's my first time to use iOS phone and I am l...  \n",
       "99  So far it’s been an AMAZING experience coming ...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")  \n",
    "driver.maximize_window()\n",
    "driver.get(\"https://www.flipkart.com/\")\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "try:\n",
    "    driver.find_element(By.XPATH,'//button[@class=\"_2KpZ6l _2doB4z\"]').click()\n",
    "except NoSuchElementException:\n",
    "    print('No login pop-up')\n",
    "    \n",
    "time.sleep(2)\n",
    "\n",
    "driver.find_element(By.XPATH,'//input[@class=\"_3704LK\"]').send_keys('iphone11')\n",
    "driver.find_element(By.XPATH,'//button[@class=\"L0Z3Pu\"]').click()\n",
    "\n",
    "time.sleep(3)\n",
    "driver.find_element(By.XPATH,'//div[@class=\"_4rR01T\"]').click()\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "driver.switch_to.window(driver.window_handles[1])\n",
    "\n",
    "driver.find_element(By.XPATH,'//div[@class=\"_3UAT2v _16PBlm\"]/span').click()\n",
    "\n",
    "rating=[]\n",
    "review_summary=[]\n",
    "full_review=[]\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "start=0\n",
    "end=10\n",
    "\n",
    "for page in range(start,end):\n",
    "    \n",
    "    rating_tag=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    for i in rating_tag[0:100]:\n",
    "        rating_all=i.text\n",
    "        rating.append(rating_all)\n",
    "    \n",
    "    summary_rs=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "    for i in summary_rs[0:100]:\n",
    "        summary_review=i.text\n",
    "        review_summary.append(summary_review)\n",
    "    \n",
    "    review_full=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]/div/div')\n",
    "    for i in review_full[0:100]:\n",
    "        review_fullAll=i.text\n",
    "        full_review.append(review_fullAll)\n",
    "\n",
    "time.sleep(4)\n",
    "\n",
    "next_page=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]/span')\n",
    "next_page.click\n",
    "time.sleep(3)\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "review_in_deep=pd.DataFrame({'Rating':rating,'Review summary':review_summary,'Full review':full_review})\n",
    "review_in_deep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e11201e",
   "metadata": {},
   "source": [
    "# Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.\n",
    "You have to scrape 4 attributes of each sneaker:\n",
    "\n",
    "1. Brand\n",
    "\n",
    "2. Product Description\n",
    "\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fb5c8283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROCKFIELD</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹424</td>\n",
       "      <td>57% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KRAFTER</td>\n",
       "      <td>Krafter denim jeans Sneakers For Men</td>\n",
       "      <td>₹499</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Layasa</td>\n",
       "      <td>supr Sneakers For Men</td>\n",
       "      <td>₹199</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Puma Smash v2 Sneakers For Men</td>\n",
       "      <td>₹2,085</td>\n",
       "      <td>58% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ONECENTRE</td>\n",
       "      <td>STR2 Sneakers For Men</td>\n",
       "      <td>₹299</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Red Rose</td>\n",
       "      <td>supr Sneakers For Men</td>\n",
       "      <td>₹499</td>\n",
       "      <td>55% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Layasa</td>\n",
       "      <td>Smash Wns v2 L Sneakers For Women</td>\n",
       "      <td>₹179</td>\n",
       "      <td>49% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Levi's Men's Lancer Sneakers Sneakers For Men</td>\n",
       "      <td>₹1,645</td>\n",
       "      <td>74% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>LEVI'S</td>\n",
       "      <td>Casual Sneaker for Men Sneakers For Men</td>\n",
       "      <td>₹1,439</td>\n",
       "      <td>71% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>pollachief</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹503</td>\n",
       "      <td>64% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Brand                            Product Description   Price Discount\n",
       "0    ROCKFIELD                               Sneakers For Men    ₹424  57% off\n",
       "1      KRAFTER           Krafter denim jeans Sneakers For Men    ₹499  50% off\n",
       "2       Layasa                          supr Sneakers For Men    ₹199  80% off\n",
       "3         PUMA                 Puma Smash v2 Sneakers For Men  ₹2,085  58% off\n",
       "4    ONECENTRE                          STR2 Sneakers For Men    ₹299  50% off\n",
       "..         ...                                            ...     ...      ...\n",
       "95    Red Rose                          supr Sneakers For Men    ₹499  55% off\n",
       "96      Layasa              Smash Wns v2 L Sneakers For Women    ₹179  49% off\n",
       "97        PUMA  Levi's Men's Lancer Sneakers Sneakers For Men  ₹1,645  74% off\n",
       "98      LEVI'S        Casual Sneaker for Men Sneakers For Men  ₹1,439  71% off\n",
       "99  pollachief                               Sneakers For Men    ₹503  64% off\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")  \n",
    "driver.maximize_window()\n",
    "driver.get(\"https://www.flipkart.com/\")\n",
    "time.sleep(3)\n",
    "try:\n",
    "    driver.find_element(By.XPATH,'//button[@class=\"_2KpZ6l _2doB4z\"]').click()\n",
    "except NoSuchElementException:\n",
    "    print('No login pop-up')\n",
    "    time.sleep(2)\n",
    "\n",
    "driver.find_element(By.XPATH,'//input[@class=\"_3704LK\"]').send_keys('sneakers')\n",
    "driver.find_element(By.XPATH,'//button[@class=\"L0Z3Pu\"]').click()\n",
    "\n",
    "time.sleep(3)\n",
    "sneakers_brand=[]\n",
    "sneakers_prodDesc=[]\n",
    "sneakers_price=[]\n",
    "sneaker_discount=[]\n",
    "time.sleep(3)\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start,end):\n",
    "    sBrand_tags=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for i in sBrand_tags[0:100]:\n",
    "        s_brand=i.text\n",
    "        sneakers_brand.append(s_brand)\n",
    "    \n",
    "    s_prodD=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa _2-ICcC\"]')\n",
    "    s_prodD1=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    \n",
    "    for i in s_prodD1[0:100]:\n",
    "        sprod_d1=i.text\n",
    "        sneakers_prodDesc.append(sprod_d1)\n",
    "    \n",
    "    for i in s_prodD[0:100]:\n",
    "        sprod_d=i.text\n",
    "        sneakers_prodDesc.append(sprod_d)\n",
    "    \n",
    "    s_price=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    for i in s_price[0:100]:\n",
    "        sprice=i.text\n",
    "        sneakers_price.append(sprice)\n",
    "        \n",
    "    sneaker_disc=driver.find_elements(By.XPATH,'//div[@class=\"_3Ay6Sb\"]/span')\n",
    "    for i in sneaker_disc[0:100]:\n",
    "        s_disc=i.text\n",
    "        sneaker_discount.append(s_disc)\n",
    "        \n",
    "time.sleep(3)\n",
    "next_page=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]/span')\n",
    "next_page.click\n",
    "time.sleep(3)\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "sneakers_dataframe=pd.DataFrame({'Brand':sneakers_brand[0:100],'Product Description':sneakers_prodDesc[0:100],'Price':sneakers_price[0:100],'Discount':sneaker_discount[0:100]})\n",
    "sneakers_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e328fcf",
   "metadata": {},
   "source": [
    "# Q7: Go to the link - https://www.myntra.com/shoes\n",
    "\n",
    "Set second Price filter and Color filter to “Black”, as shown in the below image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fdc3e4b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Men Max Cushioning Running</td>\n",
       "      <td>[Rs., 7199Rs.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men React Infinity 3 Running</td>\n",
       "      <td>[Rs., 11196Rs.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Men GO FLEX 2-COMPLETION Shoes</td>\n",
       "      <td>[Rs., 7499]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADIDAS Originals</td>\n",
       "      <td>Men Niteball II Sneakers</td>\n",
       "      <td>[Rs., 9349Rs.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Men Max Cushioning Running</td>\n",
       "      <td>[Rs., 7649Rs.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Clarks</td>\n",
       "      <td>Men Leather Derbys</td>\n",
       "      <td>[Rs., 7499]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ADIDAS Originals</td>\n",
       "      <td>Men Woven NMD_31 Sneakers</td>\n",
       "      <td>[Rs., 11199Rs.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Unisex Accelerate Badminton</td>\n",
       "      <td>[Rs., 7199Rs.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ADIDAS Originals</td>\n",
       "      <td>Men Ozweego Sneakers</td>\n",
       "      <td>[Rs., 10999]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Men Lockdown 5 Basketball</td>\n",
       "      <td>[Rs., 6999]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Brand             Product Description            Price\n",
       "0           Skechers      Men Max Cushioning Running   [Rs., 7199Rs.]\n",
       "1               Nike    Men React Infinity 3 Running  [Rs., 11196Rs.]\n",
       "2           Skechers  Men GO FLEX 2-COMPLETION Shoes      [Rs., 7499]\n",
       "3   ADIDAS Originals        Men Niteball II Sneakers   [Rs., 9349Rs.]\n",
       "4           Skechers      Men Max Cushioning Running   [Rs., 7649Rs.]\n",
       "..               ...                             ...              ...\n",
       "95            Clarks              Men Leather Derbys      [Rs., 7499]\n",
       "96  ADIDAS Originals       Men Woven NMD_31 Sneakers  [Rs., 11199Rs.]\n",
       "97              Puma     Unisex Accelerate Badminton   [Rs., 7199Rs.]\n",
       "98  ADIDAS Originals            Men Ozweego Sneakers     [Rs., 10999]\n",
       "99      UNDER ARMOUR       Men Lockdown 5 Basketball      [Rs., 6999]\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")  \n",
    "driver.maximize_window()\n",
    "driver.get(\"https://www.myntra.com/shoes\")\n",
    "\n",
    "time.sleep(5)\n",
    "driver.find_element(By.XPATH,'//span[@data-colorhex=\"black\"]').click()\n",
    "time.sleep(5)\n",
    "driver.find_element(By.XPATH,'/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label').click()\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "shoe_brand=[]\n",
    "shoe_desc=[]\n",
    "shoe_price=[]\n",
    "\n",
    "start=0\n",
    "end=2\n",
    "for page in range(start,end):\n",
    "    shoeB_tags=driver.find_elements(By.XPATH,'//h3[@class=\"product-brand\"]')\n",
    "    for i in shoeB_tags[0:100]:\n",
    "        s_brand=i.text\n",
    "        shoe_brand.append(s_brand)\n",
    "        \n",
    "    shoeD_tags=driver.find_elements(By.XPATH,'//h4[@class=\"product-product\"]')\n",
    "    for i in shoeD_tags[0:100]:\n",
    "        s_desc=i.text\n",
    "        shoe_desc.append(s_desc)\n",
    "        \n",
    "    shoeP_tags=driver.find_elements(By.XPATH,'//div[@class=\"product-price\"]')\n",
    "    for i in shoeP_tags[0:100]:\n",
    "        s_price=i.text.split(\" \")[0:2]\n",
    "        shoe_price.append(s_price)\n",
    "    \n",
    "time.sleep(3)\n",
    "next_button=driver.find_element(By.XPATH,'//a[@rel=\"next\"]')\n",
    "next_button.click\n",
    "time.sleep(3)\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "myntra_shoe=pd.DataFrame({'Brand':shoe_brand,'Product Description':shoe_desc,'Price':shoe_price})\n",
    "myntra_shoe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c4453f",
   "metadata": {},
   "source": [
    "# Q8: Go to webpage https://www.amazon.in/ Enter “Laptop” in the search field and then click the search icon. Then set CPU Type filter to “Intel Core i7” as shown in the below image:\n",
    "    \n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributesfor each laptop:\n",
    "    \n",
    "1. Title\n",
    "\n",
    "2. Ratings\n",
    "\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4f1be587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Samsung Galaxy Book2 Intel 12th Gen core i7 39...</td>\n",
       "      <td>3.6 out of 5 stars</td>\n",
       "      <td>₹79,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Samsung Galaxy Book2 Pro 360 Intel 12th Gen i7...</td>\n",
       "      <td>3.5 out of 5 stars</td>\n",
       "      <td>₹1,29,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lenovo Ideapad Gaming 3 Intel Core i7 10th Gen...</td>\n",
       "      <td>3.9 out of 5 stars</td>\n",
       "      <td>₹59,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lenovo IdeaPad Slim 5 Intel Core i7 12th Gen 1...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>₹81,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Samsung Galaxy Book2 Intel 12th Gen core i7 39...</td>\n",
       "      <td>3.6 out of 5 stars</td>\n",
       "      <td>₹79,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>₹89,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...</td>\n",
       "      <td>3.7 out of 5 stars</td>\n",
       "      <td>₹54,848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hp Pavilion X360 11Th Gen Intel Core I7 14 Inc...</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "      <td>₹82,400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HP Pavilion 14 12th Gen Intel Core i7 16GB SDR...</td>\n",
       "      <td>3.9 out of 5 stars</td>\n",
       "      <td>₹87,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fujitsu UH-X 11th Gen Intel Core i7 13.3” FHD ...</td>\n",
       "      <td>4.5 out of 5 stars</td>\n",
       "      <td>₹84,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title              Rating  \\\n",
       "0  Samsung Galaxy Book2 Intel 12th Gen core i7 39...  3.6 out of 5 stars   \n",
       "1  Samsung Galaxy Book2 Pro 360 Intel 12th Gen i7...  3.5 out of 5 stars   \n",
       "2  Lenovo Ideapad Gaming 3 Intel Core i7 10th Gen...  3.9 out of 5 stars   \n",
       "3  Lenovo IdeaPad Slim 5 Intel Core i7 12th Gen 1...  5.0 out of 5 stars   \n",
       "4  Samsung Galaxy Book2 Intel 12th Gen core i7 39...  3.6 out of 5 stars   \n",
       "5  HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...  4.2 out of 5 stars   \n",
       "6  ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...  3.7 out of 5 stars   \n",
       "7  Hp Pavilion X360 11Th Gen Intel Core I7 14 Inc...  4.0 out of 5 stars   \n",
       "8  HP Pavilion 14 12th Gen Intel Core i7 16GB SDR...  3.9 out of 5 stars   \n",
       "9  Fujitsu UH-X 11th Gen Intel Core i7 13.3” FHD ...  4.5 out of 5 stars   \n",
       "\n",
       "       Price  \n",
       "0    ₹79,490  \n",
       "1  ₹1,29,990  \n",
       "2    ₹59,990  \n",
       "3    ₹81,990  \n",
       "4    ₹79,490  \n",
       "5    ₹89,990  \n",
       "6    ₹54,848  \n",
       "7    ₹82,400  \n",
       "8    ₹87,990  \n",
       "9    ₹84,990  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")  \n",
    "driver.maximize_window()\n",
    "driver.get(\"https://www.amazon.in/\")\n",
    "\n",
    "textBox=driver.find_element(By.ID,'twotabsearchtextbox')\n",
    "textBox.send_keys('Laptop')\n",
    "\n",
    "submit=driver.find_element(By.ID,'nav-search-submit-button')\n",
    "submit.click()\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "cpu_type=driver.find_element(By.XPATH,'//*[@id=\"p_n_feature_thirteen_browse-bin/12598163031\"]/span/a/span')\n",
    "cpu_type.click()\n",
    "\n",
    "time.sleep(3)\n",
    "product_title=[]\n",
    "product_rating=[]\n",
    "product_price=[]\n",
    "\n",
    "title_tags=driver.find_elements(By.XPATH,'//span[@class=\"a-size-medium a-color-base a-text-normal\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    product_title.append(i.text)\n",
    "    \n",
    "product_tags=driver.find_elements(By.XPATH,'//div[@class=\"a-row a-size-small\"]/span[1]')\n",
    "for i in product_tags[0:10]:\n",
    "    rating=i.get_attribute('aria-label')\n",
    "    product_rating.append(rating)\n",
    "    \n",
    "price_tags=driver.find_elements(By.XPATH,'//span[@class=\"a-price\"]')\n",
    "for i in price_tags[0:10]:\n",
    "    product_price.append(i.text)\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "laptop_dataFrame=pd.DataFrame({'Title':product_title,'Rating':product_rating,'Price':product_price})\n",
    "laptop_dataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a562f6ce",
   "metadata": {},
   "source": [
    "# Q9: Write a python program to scrape data for first 10 job results for Data Scientist Designation in Noida location. \n",
    "You have to scrape company name, No. of days ago when job was posted, Rating of the company.\n",
    "\n",
    "This task will be done in following steps:\n",
    "\n",
    "1. First get the webpage https://www.ambitionbox.com/\n",
    "\n",
    "2. Click on the Job option as shown in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e5a0e6cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>No. of days ago when job was posted</th>\n",
       "      <th>Rating of the company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CBRE South Asia Pvt Ltd</td>\n",
       "      <td>2d ago</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ericsson India Global Services Pvt. Ltd.</td>\n",
       "      <td>12d ago</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>5d ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Optum Global Solutions (India) Private Limited</td>\n",
       "      <td>9d ago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Optum Global Solutions (India) Private Limited</td>\n",
       "      <td>10d ago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ericsson India Global Services Pvt. Ltd.</td>\n",
       "      <td>22d ago</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SOPRA STERIA INDIA LIMITED</td>\n",
       "      <td>11d ago</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EXL Services.com ( I ) Pvt. Ltd.</td>\n",
       "      <td>11d ago</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EY</td>\n",
       "      <td>21d ago</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CARE HEALTH INSURANCE LIMITED</td>\n",
       "      <td>26d ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Company Name  \\\n",
       "0                         CBRE South Asia Pvt Ltd   \n",
       "1        Ericsson India Global Services Pvt. Ltd.   \n",
       "2                   GENPACT India Private Limited   \n",
       "3  Optum Global Solutions (India) Private Limited   \n",
       "4  Optum Global Solutions (India) Private Limited   \n",
       "5        Ericsson India Global Services Pvt. Ltd.   \n",
       "6                      SOPRA STERIA INDIA LIMITED   \n",
       "7                EXL Services.com ( I ) Pvt. Ltd.   \n",
       "8                                              EY   \n",
       "9                   CARE HEALTH INSURANCE LIMITED   \n",
       "\n",
       "  No. of days ago when job was posted Rating of the company  \n",
       "0                              2d ago                   4.3  \n",
       "1                             12d ago                   4.3  \n",
       "2                              5d ago                   4.0  \n",
       "3                              9d ago                   4.1  \n",
       "4                             10d ago                   4.1  \n",
       "5                             22d ago                   4.3  \n",
       "6                             11d ago                   4.2  \n",
       "7                             11d ago                   3.9  \n",
       "8                             21d ago                   3.8  \n",
       "9                             26d ago                   4.0  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")  \n",
    "driver.maximize_window()\n",
    "driver.get(\"https://www.ambitionbox.com/\")\n",
    "\n",
    "Designation='Data Scientist'\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "driver.find_element(By.XPATH,'//a[@title=\"Jobs\"]').click()\n",
    "driver.find_element(By.XPATH,'//input[@title=\"Enter Designation, Company or a Skill\"]').send_keys(Designation)\n",
    "driver.find_element(By.XPATH,'//button[@class=\"ab_btn search-btn round\"]/span[1]').click()\n",
    "time.sleep(3)\n",
    "\n",
    "driver.find_element(By.XPATH,'//div[@title=\"Location\"]').click()\n",
    "time.sleep(2)\n",
    "driver.find_element(By.XPATH,'//input[@placeholder=\"Search locations\"]').send_keys('Noida')\n",
    "driver.find_element(By.XPATH,'//label[@for=\"location_Noida\"]').click()\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "co_name=[]\n",
    "no_of_days=[]\n",
    "rating_co=[]\n",
    "\n",
    "#Scraping Company Name\n",
    "comp_name=driver.find_elements(By.XPATH,'//p[@class=\"company body-medium\"]')\n",
    "for i in comp_name[0:10]:\n",
    "    cname=i.text\n",
    "    co_name.append(cname)\n",
    "\n",
    "#Scraping No. of days ago when job was posted \n",
    "no_days=driver.find_elements(By.XPATH,'//div[@class=\"other-info\"]/span[1]')\n",
    "for i in no_days[0:10]:\n",
    "    noofdays=i.text\n",
    "    no_of_days.append(noofdays)\n",
    "\n",
    "#Scraping Rating of the company\n",
    "comp_rating=driver.find_elements(By.XPATH,'//span[@class=\"body-small\"]')\n",
    "for i in comp_rating[0:10]:\n",
    "    comRating=i.text\n",
    "    rating_co.append(comRating)\n",
    "    \n",
    "time.sleep(3)\n",
    "driver.quit() #closing all active window opened by selenium\n",
    "\n",
    "#DataFrame for Job posted on ambitionbox\n",
    "ambitionbox=pd.DataFrame({'Company Name':co_name,'No. of days ago when job was posted':no_of_days,'Rating of the company':rating_co})\n",
    "ambitionbox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da6d291",
   "metadata": {},
   "source": [
    "# Q10: Write a python program to scrape the salary data for Data Scientist designation.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Minsalary, Max Salary.\n",
    "\n",
    "The above task will be, done as shown in the below steps:\n",
    "    \n",
    "1. First get the webpage https://www.ambitionbox.com/\n",
    "\n",
    "2. Click on the salaries option as shown in the image.\n",
    "\n",
    "3. After reaching to the following webpage, In place of “Search Job Profile” enters “Data Scientist” and\n",
    "then click on “Data Scientist”.\n",
    "\n",
    "4. Scrape the data for the first 10 companies. Scrape the company name, total salary record, average\n",
    "salary, minimum salary, maximum salary, experience required.\n",
    "\n",
    "5. Store the data in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "c909da0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company name</th>\n",
       "      <th>Total salary record</th>\n",
       "      <th>average salary</th>\n",
       "      <th>Minimum salary</th>\n",
       "      <th>Maximum salary</th>\n",
       "      <th>Experience required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>based on 22 salaries</td>\n",
       "      <td>₹ 31.7L</td>\n",
       "      <td>₹ 25.0L</td>\n",
       "      <td>₹ 45.0L</td>\n",
       "      <td>3-4 yrs experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ab Inbev</td>\n",
       "      <td>based on 50 salaries</td>\n",
       "      <td>₹ 19.7L</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>₹ 25.5L</td>\n",
       "      <td>2-4 yrs experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Optum</td>\n",
       "      <td>based on 48 salaries</td>\n",
       "      <td>₹ 16.5L</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 22.6L</td>\n",
       "      <td>2-4 yrs experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZS</td>\n",
       "      <td>based on 32 salaries</td>\n",
       "      <td>₹ 15.7L</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 22.0L</td>\n",
       "      <td>1-2 yrs experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>based on 105 salaries</td>\n",
       "      <td>₹ 15.1L</td>\n",
       "      <td>₹ 9.0L</td>\n",
       "      <td>₹ 23.0L</td>\n",
       "      <td>2-4 yrs experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tiger Analytics</td>\n",
       "      <td>based on 60 salaries</td>\n",
       "      <td>₹ 14.6L</td>\n",
       "      <td>₹ 9.0L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "      <td>2-4 yrs experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Legato Health Technologies</td>\n",
       "      <td>based on 11 salaries</td>\n",
       "      <td>₹ 14.6L</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "      <td>4 yrs experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tredence</td>\n",
       "      <td>based on 10 salaries</td>\n",
       "      <td>₹ 13.9L</td>\n",
       "      <td>₹ 8.8L</td>\n",
       "      <td>₹ 17.5L</td>\n",
       "      <td>3 yrs experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>UnitedHealth</td>\n",
       "      <td>based on 90 salaries</td>\n",
       "      <td>₹ 13.7L</td>\n",
       "      <td>₹ 8.0L</td>\n",
       "      <td>₹ 20.5L</td>\n",
       "      <td>2-4 yrs experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Reliance jio</td>\n",
       "      <td>based on 45 salaries</td>\n",
       "      <td>₹ 13.6L</td>\n",
       "      <td>₹ 6.0L</td>\n",
       "      <td>₹ 26.2L</td>\n",
       "      <td>1-4 yrs experience</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Company name    Total salary record average salary  \\\n",
       "0                     Walmart    based on 22 salaries        ₹ 31.7L   \n",
       "1                    Ab Inbev    based on 50 salaries        ₹ 19.7L   \n",
       "2                       Optum    based on 48 salaries        ₹ 16.5L   \n",
       "3                          ZS    based on 32 salaries        ₹ 15.7L   \n",
       "4           Fractal Analytics   based on 105 salaries        ₹ 15.1L   \n",
       "5             Tiger Analytics    based on 60 salaries        ₹ 14.6L   \n",
       "6  Legato Health Technologies    based on 11 salaries        ₹ 14.6L   \n",
       "7                    Tredence    based on 10 salaries        ₹ 13.9L   \n",
       "8                UnitedHealth    based on 90 salaries        ₹ 13.7L   \n",
       "9                Reliance jio    based on 45 salaries        ₹ 13.6L   \n",
       "\n",
       "  Minimum salary Maximum salary  Experience required  \n",
       "0        ₹ 25.0L        ₹ 45.0L  3-4 yrs experience   \n",
       "1        ₹ 15.0L        ₹ 25.5L  2-4 yrs experience   \n",
       "2        ₹ 11.0L        ₹ 22.6L  2-4 yrs experience   \n",
       "3        ₹ 11.0L        ₹ 22.0L  1-2 yrs experience   \n",
       "4         ₹ 9.0L        ₹ 23.0L  2-4 yrs experience   \n",
       "5         ₹ 9.0L        ₹ 20.0L  2-4 yrs experience   \n",
       "6        ₹ 11.0L        ₹ 20.0L    4 yrs experience   \n",
       "7         ₹ 8.8L        ₹ 17.5L    3 yrs experience   \n",
       "8         ₹ 8.0L        ₹ 20.5L  2-4 yrs experience   \n",
       "9         ₹ 6.0L        ₹ 26.2L  1-4 yrs experience   "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")  \n",
    "driver.maximize_window()\n",
    "driver.get(\"https://www.ambitionbox.com/\")\n",
    "\n",
    "driver.implicitly_wait(5)\n",
    "\n",
    "driver.find_element(By.XPATH,'/html[1]/body[1]/div[1]/nav[2]/div[1]/ul[1]/li[3]/a[1]').click()\n",
    "\n",
    "driver.find_element(By.XPATH,'/html[1]/body[1]/div[1]/nav[2]/div[1]/ul[1]/li[3]/div[1]/ul[1]/li[1]/div[1]').click()\n",
    "\n",
    "time.sleep(3)\n",
    "search=driver.find_element(By.ID,'jobProfileSearchbox')\n",
    "search.click()\n",
    "time.sleep(3)\n",
    "search.send_keys('Data Scientist')\n",
    "time.sleep(3)\n",
    "search.send_keys(Keys.ARROW_DOWN)\n",
    "\n",
    "search.send_keys(Keys.ENTER)\n",
    "\n",
    "\n",
    "company_name=[]\n",
    "total_salary_record=[]\n",
    "average_salary=[]\n",
    "minimum_salary=[]\n",
    "maximum_salary=[]\n",
    "experience_required=[]\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "coName=driver.find_elements(By.XPATH,'//div[@class=\"company-info\"]/a')\n",
    "for i in coName[0:10]:\n",
    "    co_a_name=i.get_attribute('title').split('Data Scientist Salary')[0]\n",
    "    company_name.append(co_a_name)\n",
    "    \n",
    "totalSalRecord=driver.find_elements(By.XPATH,'//span[@class=\"datapoints\"]')\n",
    "for i in totalSalRecord[0:10]:\n",
    "    total_sal=i.text.replace('(',\"\").replace(\")\",\"\")\n",
    "    total_salary_record.append(total_sal)\n",
    "    \n",
    "avg_salary=driver.find_elements(By.XPATH,'//p[@class=\"averageCtc\"]')\n",
    "for i in avg_salary[0:10]:\n",
    "    sal_avg=i.text\n",
    "    average_salary.append(sal_avg)\n",
    "    \n",
    "min_sal=driver.find_elements(By.XPATH,'//div[@class=\"salary-values\"]/div[1]')\n",
    "for i in min_sal[0:10]:\n",
    "    sal_min=i.text\n",
    "    minimum_salary.append(sal_min)\n",
    "    \n",
    "max_salary=driver.find_elements(By.XPATH,'//div[@class=\"salary-values\"]/div[2]')\n",
    "for i in max_salary[0:10]:\n",
    "    sal_max=i.text\n",
    "    maximum_salary.append(sal_max)\n",
    "\n",
    "exp_req=driver.find_elements(By.XPATH,'//div[@class=\"sbold-list-header\"]')\n",
    "for i in exp_req[0:10]:\n",
    "    required_exp=i.text.split(\"(\")[0]\n",
    "    experience_required.append(required_exp)\n",
    "    \n",
    "driver.quit()\n",
    "\n",
    "salary_comparison=pd.DataFrame({'Company name':company_name,'Total salary record':total_salary_record,'average salary':average_salary,'Minimum salary':minimum_salary,'Maximum salary':maximum_salary,'Experience required':experience_required})\n",
    "salary_comparison"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
