{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f38a4a88",
   "metadata": {},
   "source": [
    "# Q1- Write a python program to display all the header tags from wikipedia.org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6fc9256",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required packages\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fb8de94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki=requests.get('https://en.wikipedia.org/wiki/Main_Page') #Checking response status\n",
    "wiki "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84cccc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "WikiPageContent=BeautifulSoup(wiki.content) #getting Page content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c32c3573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Welcome to Wikipedia',\n",
       " \"From today's featured article\",\n",
       " 'Did you know\\xa0...',\n",
       " 'In the news',\n",
       " 'On this day',\n",
       " \"Today's featured picture\",\n",
       " 'Other areas of Wikipedia',\n",
       " \"Wikipedia's sister projects\",\n",
       " 'Wikipedia languages']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_header=[] #Creating a blank arrayList\n",
    "for i in WikiPageContent.find_all('span',class_='mw-headline'):\n",
    "    wiki_header.append(i.text)\n",
    "wiki_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2eb04523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wikipedia Page Headers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Welcome to Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From today's featured article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Did you know ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In the news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>On this day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Today's featured picture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Other areas of Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wikipedia's sister projects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wikipedia languages</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Wikipedia Page Headers\n",
       "0           Welcome to Wikipedia\n",
       "1  From today's featured article\n",
       "2               Did you know ...\n",
       "3                    In the news\n",
       "4                    On this day\n",
       "5       Today's featured picture\n",
       "6       Other areas of Wikipedia\n",
       "7    Wikipedia's sister projects\n",
       "8            Wikipedia languages"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WikiHeader=pd.DataFrame({'Wikipedia Page Headers':wiki_header})\n",
    "WikiHeader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d18c03",
   "metadata": {},
   "source": [
    "# Q2-Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. name, rating, year of release) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99786d93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Imdb_url=requests.get('https://www.imdb.com/list/ls055592025/')\n",
    "Imdb_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8e184d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Imdb_Page=BeautifulSoup(Imdb_url.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8cf41c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Godfather',\n",
       " 'The Shawshank Redemption',\n",
       " \"Schindler's List\",\n",
       " 'Raging Bull',\n",
       " 'Casablanca',\n",
       " 'Citizen Kane',\n",
       " 'Gone with the Wind',\n",
       " 'The Wizard of Oz',\n",
       " \"One Flew Over the Cuckoo's Nest\",\n",
       " 'Lawrence of Arabia',\n",
       " 'Vertigo',\n",
       " 'Psycho',\n",
       " 'The Godfather Part II',\n",
       " 'On the Waterfront',\n",
       " 'Sunset Blvd',\n",
       " 'Forrest Gump',\n",
       " 'The Sound of Music',\n",
       " '12 Angry Men',\n",
       " 'West Side Story',\n",
       " 'Star Wars',\n",
       " '2001: A Space Odyssey',\n",
       " 'E',\n",
       " 'The Silence of the Lambs',\n",
       " 'Chinatown',\n",
       " 'The Bridge on the River Kwai',\n",
       " \"Singin' in the Rain\",\n",
       " \"It's a Wonderful Life\",\n",
       " 'Dr',\n",
       " 'Some Like It Hot',\n",
       " 'Ben-Hur',\n",
       " 'Apocalypse Now',\n",
       " 'Amadeus',\n",
       " 'The Lord of the Rings: The Return of the King',\n",
       " 'Gladiator',\n",
       " 'Titanic',\n",
       " 'From Here to Eternity',\n",
       " 'Saving Private Ryan',\n",
       " 'Unforgiven',\n",
       " 'Raiders of the Lost Ark',\n",
       " 'Rocky',\n",
       " 'A Streetcar Named Desire',\n",
       " 'The Philadelphia Story',\n",
       " 'To Kill a Mockingbird',\n",
       " 'An American in Paris',\n",
       " 'The Best Years of Our Lives',\n",
       " 'My Fair Lady',\n",
       " 'A Clockwork Orange',\n",
       " 'Doctor Zhivago',\n",
       " 'The Searchers',\n",
       " 'Jaws',\n",
       " 'Patton',\n",
       " 'Butch Cassidy and the Sundance Kid',\n",
       " 'The Treasure of the Sierra Madre',\n",
       " 'Il buono, il brutto, il cattivo',\n",
       " 'The Apartment',\n",
       " 'Platoon',\n",
       " 'High Noon',\n",
       " 'Braveheart',\n",
       " 'Dances with Wolves',\n",
       " 'Jurassic Park',\n",
       " 'The Exorcist',\n",
       " 'The Pianist',\n",
       " 'Goodfellas',\n",
       " 'The Deer Hunter',\n",
       " 'All Quiet on the Western Front',\n",
       " 'Bonnie and Clyde',\n",
       " 'The French Connection',\n",
       " 'City Lights',\n",
       " 'It Happened One Night',\n",
       " 'A Place in the Sun',\n",
       " 'Midnight Cowboy',\n",
       " 'Mr',\n",
       " 'Rain Man',\n",
       " 'Annie Hall',\n",
       " 'Fargo',\n",
       " 'Giant',\n",
       " 'Shane',\n",
       " 'The Grapes of Wrath',\n",
       " 'The Green Mile',\n",
       " 'Close Encounters of the Third Kind',\n",
       " 'Nashville',\n",
       " 'Network',\n",
       " 'The Graduate',\n",
       " 'American Graffiti',\n",
       " 'Pulp Fiction',\n",
       " 'Terms of Endearment',\n",
       " 'Good Will Hunting',\n",
       " 'The African Queen',\n",
       " 'Stagecoach',\n",
       " 'Mutiny on the Bounty',\n",
       " 'The Great Dictator',\n",
       " 'Double Indemnity',\n",
       " 'The Maltese Falcon',\n",
       " 'Wuthering Heights',\n",
       " 'Taxi Driver',\n",
       " 'Rear Window',\n",
       " 'The Third Man',\n",
       " 'Rebel Without a Cause',\n",
       " 'North by Northwest',\n",
       " 'Yankee Doodle Dandy']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_name=[] #List to extract all top 100 movies names\n",
    "\n",
    "for i in Imdb_Page.find_all('h3',class_='lister-item-header'):\n",
    "    movie_name.append(i.text.split(\".\")[1].split(\"(\")[0].strip())\n",
    "    \n",
    "movie_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43be4801",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1972',\n",
       " '1994',\n",
       " '1993',\n",
       " '1980',\n",
       " '1942',\n",
       " '1941',\n",
       " '1939',\n",
       " '1939',\n",
       " '1975',\n",
       " '1962',\n",
       " '1958',\n",
       " '1960',\n",
       " '1974',\n",
       " '1954',\n",
       " '1950',\n",
       " '1994',\n",
       " '1965',\n",
       " '1957',\n",
       " '1961',\n",
       " '1977',\n",
       " '1968',\n",
       " '1982',\n",
       " '1991',\n",
       " '1974',\n",
       " '1957',\n",
       " '1952',\n",
       " '1946',\n",
       " '1964',\n",
       " '1959',\n",
       " '1959',\n",
       " '1979',\n",
       " '1984',\n",
       " '2003',\n",
       " '2000',\n",
       " '1997',\n",
       " '1953',\n",
       " '1998',\n",
       " '1992',\n",
       " '1981',\n",
       " '1976',\n",
       " '1951',\n",
       " '1940',\n",
       " '1962',\n",
       " '1951',\n",
       " '1946',\n",
       " '1964',\n",
       " '1971',\n",
       " '1965',\n",
       " '1956',\n",
       " '1975',\n",
       " '1970',\n",
       " '1969',\n",
       " '1948',\n",
       " '1966',\n",
       " '1960',\n",
       " '1986',\n",
       " '1952',\n",
       " '1995',\n",
       " '1990',\n",
       " '1993',\n",
       " '1973',\n",
       " '2002',\n",
       " '1990',\n",
       " '1978',\n",
       " '1930',\n",
       " '1967',\n",
       " '1971',\n",
       " '1931',\n",
       " '1934',\n",
       " '1951',\n",
       " '1969',\n",
       " '1939',\n",
       " '1988',\n",
       " '1977',\n",
       " '1996',\n",
       " '1956',\n",
       " '1953',\n",
       " '1940',\n",
       " '1999',\n",
       " '1977',\n",
       " '1975',\n",
       " '1976',\n",
       " '1967',\n",
       " '1973',\n",
       " '1994',\n",
       " '1983',\n",
       " '1997',\n",
       " '1951',\n",
       " '1939',\n",
       " '1935',\n",
       " '1940',\n",
       " '1944',\n",
       " '1941',\n",
       " '1939',\n",
       " '1976',\n",
       " '1954',\n",
       " '1949',\n",
       " '1955',\n",
       " '1959',\n",
       " '1942']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_year=[] #List to extract all top 100 movies years\n",
    "for i in Imdb_Page.find_all('h3',class_='lister-item-header'):\n",
    "    movie_year.append(i.text.split(\"(\")[1].replace(\")\",\"\").strip())\n",
    "movie_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f086f5dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9.2',\n",
       " '9.3',\n",
       " '9',\n",
       " '8.2',\n",
       " '8.5',\n",
       " '8.3',\n",
       " '8.2',\n",
       " '8.1',\n",
       " '8.7',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.5',\n",
       " '9',\n",
       " '8.1',\n",
       " '8.4',\n",
       " '8.8',\n",
       " '8.1',\n",
       " '9',\n",
       " '7.6',\n",
       " '8.6',\n",
       " '8.3',\n",
       " '7.9',\n",
       " '8.6',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.3',\n",
       " '8.6',\n",
       " '8.4',\n",
       " '8.2',\n",
       " '8.1',\n",
       " '8.5',\n",
       " '8.4',\n",
       " '9',\n",
       " '8.5',\n",
       " '7.9',\n",
       " '7.6',\n",
       " '8.6',\n",
       " '8.2',\n",
       " '8.4',\n",
       " '8.1',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '8.3',\n",
       " '7.2',\n",
       " '8.1',\n",
       " '7.8',\n",
       " '8.3',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '8.1',\n",
       " '7.9',\n",
       " '8',\n",
       " '8.2',\n",
       " '8.8',\n",
       " '8.3',\n",
       " '8.1',\n",
       " '8',\n",
       " '8.4',\n",
       " '8',\n",
       " '8.2',\n",
       " '8.1',\n",
       " '8.5',\n",
       " '8.7',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '8.5',\n",
       " '8.1',\n",
       " '7.7',\n",
       " '7.8',\n",
       " '8.1',\n",
       " '8',\n",
       " '8',\n",
       " '8.1',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '8.1',\n",
       " '8.6',\n",
       " '7.6',\n",
       " '7.7',\n",
       " '8.1',\n",
       " '8',\n",
       " '7.4',\n",
       " '8.9',\n",
       " '7.4',\n",
       " '8.3',\n",
       " '7.7',\n",
       " '7.8',\n",
       " '7.7',\n",
       " '8.4',\n",
       " '8.3',\n",
       " '8',\n",
       " '7.5',\n",
       " '8.2',\n",
       " '8.5',\n",
       " '8.1',\n",
       " '7.6',\n",
       " '8.3',\n",
       " '7.6']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_rating=[] #List to extract all top 100 movies rating\n",
    "\n",
    "for i in Imdb_Page.find_all('div',class_=\"ipl-rating-widget\"):\n",
    "    movie_rating.append(i.text.strip().split()[0])\n",
    "    \n",
    "movie_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40d3d48c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie Name</th>\n",
       "      <th>Year of release</th>\n",
       "      <th>Movie Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>1972</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>1994</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Schindler's List</td>\n",
       "      <td>1993</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Raging Bull</td>\n",
       "      <td>1980</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Casablanca</td>\n",
       "      <td>1942</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Rear Window</td>\n",
       "      <td>1954</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>The Third Man</td>\n",
       "      <td>1949</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Rebel Without a Cause</td>\n",
       "      <td>1955</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>North by Northwest</td>\n",
       "      <td>1959</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Yankee Doodle Dandy</td>\n",
       "      <td>1942</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Movie Name Year of release Movie Rating\n",
       "0              The Godfather            1972          9.2\n",
       "1   The Shawshank Redemption            1994          9.3\n",
       "2           Schindler's List            1993            9\n",
       "3                Raging Bull            1980          8.2\n",
       "4                 Casablanca            1942          8.5\n",
       "..                       ...             ...          ...\n",
       "95               Rear Window            1954          8.5\n",
       "96             The Third Man            1949          8.1\n",
       "97     Rebel Without a Cause            1955          7.6\n",
       "98        North by Northwest            1959          8.3\n",
       "99       Yankee Doodle Dandy            1942          7.6\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Imbd=pd.DataFrame({'Movie Name':movie_name,'Year of release':movie_year,'Movie Rating':movie_rating})\n",
    "Imbd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05e2946",
   "metadata": {},
   "source": [
    "# Q3-Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. name, rating, year of release) and make data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13ebf7f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Imdb_url2=requests.get('https://www.imdb.com/list/ls009997493/')\n",
    "Imdb_url2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e954bddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Imdb_Page2=BeautifulSoup(Imdb_url2.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e23b8a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie Name</th>\n",
       "      <th>Year of release</th>\n",
       "      <th>Movie Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rang De Basanti</td>\n",
       "      <td>2006</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3 Idiots</td>\n",
       "      <td>2009</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Taare Zameen Par</td>\n",
       "      <td>2007</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dil Chahta Hai</td>\n",
       "      <td>2001</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Swades: We, the People</td>\n",
       "      <td>2004</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Wake Up Sid</td>\n",
       "      <td>2009</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Rangeela</td>\n",
       "      <td>1995</td>\n",
       "      <td>7.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Shatranj Ke Khilari</td>\n",
       "      <td>1977</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Pyaar Ka Punchnama</td>\n",
       "      <td>2011</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Ek Hasina Thi</td>\n",
       "      <td>2004</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Movie Name Year of release Movie Rating\n",
       "0          Rang De Basanti            2006          8.1\n",
       "1                 3 Idiots            2009          8.4\n",
       "2         Taare Zameen Par            2007          8.3\n",
       "3           Dil Chahta Hai            2001          8.1\n",
       "4   Swades: We, the People            2004          8.1\n",
       "..                     ...             ...          ...\n",
       "95             Wake Up Sid            2009          7.6\n",
       "96                Rangeela            1995          7.4\n",
       "97     Shatranj Ke Khilari            1977          7.5\n",
       "98      Pyaar Ka Punchnama            2011          7.6\n",
       "99           Ek Hasina Thi            2004          7.5\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_name2=[]\n",
    "movie_year2=[]\n",
    "movie_rating2=[]\n",
    "\n",
    "for i in Imdb_Page2.find_all('h3',class_='lister-item-header'):\n",
    "    movie_name2.append(i.text.split(\".\")[1].split(\"(\")[0].strip())\n",
    "    \n",
    "\n",
    "for i in Imdb_Page2.find_all('h3',class_='lister-item-header'):\n",
    "    movie_year2.append(i.text.split(\"(\")[1].replace(\")\",\"\").strip())\n",
    "    \n",
    "for i in Imdb_Page2.find_all('div',class_=\"ipl-rating-widget\"):\n",
    "    movie_rating2.append(i.text.strip().split()[0])\n",
    "    \n",
    "Imbd_hindi=pd.DataFrame({'Movie Name':movie_name2,'Year of release':movie_year2,'Movie Rating':movie_rating2})\n",
    "Imbd_hindi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ac6e49",
   "metadata": {},
   "source": [
    "# Q4 Write s python program to display list of respected former presidents of India(i.e. Name , Term of office) from https://presidentofindia.nic.in/former-presidents.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a76a4e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfp_india_url=requests.get('https://presidentofindia.nic.in/former-presidents.htm')\n",
    "rfp_india_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5518e4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfp_india_page=BeautifulSoup(rfp_india_url.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe7588f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Shri Ram Nath Kovind ',\n",
       " 'Shri Pranab Mukherjee ',\n",
       " 'Smt Pratibha Devisingh Patil ',\n",
       " 'DR. A.P.J. Abdul Kalam ',\n",
       " 'Shri K. R. Narayanan ',\n",
       " 'Dr Shankar Dayal Sharma ',\n",
       " 'Shri R Venkataraman ',\n",
       " 'Giani Zail Singh ',\n",
       " 'Shri Neelam Sanjiva Reddy ',\n",
       " 'Dr. Fakhruddin Ali Ahmed ',\n",
       " 'Shri Varahagiri Venkata Giri ',\n",
       " 'Dr. Zakir Husain ',\n",
       " 'Dr. Sarvepalli Radhakrishnan ',\n",
       " 'Dr. Rajendra Prasad ']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "presidents_name=[]\n",
    "\n",
    "for i in rfp_india_page.find_all('h3'):\n",
    "    presidents_name.append(i.text.split(\"(\")[0])\n",
    "presidents_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a3c4b1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' 25 July, 2017 to 25 July, 2022 ',\n",
       " ' 25 July, 2012 to 25 July, 2017 ',\n",
       " ' 25 July, 2007 to 25 July, 2012 ',\n",
       " ' 25 July, 2002 to 25 July, 2007 ',\n",
       " ' 25 July, 1997 to 25 July, 2002 ',\n",
       " ' 25 July, 1992 to 25 July, 1997 ',\n",
       " ' 25 July, 1987 to 25 July, 1992 ',\n",
       " ' 25 July, 1982 to 25 July, 1987 ',\n",
       " ' 25 July, 1977 to 25 July, 1982 ',\n",
       " ' 24 August, 1974 to 11 February, 1977',\n",
       " ' 3 May, 1969 to 20 July, 1969 and 24 August, 1969 to 24 August, 1974',\n",
       " ' 13 May, 1967 to 3 May, 1969',\n",
       " ' 13 May, 1962 to 13 May, 1967',\n",
       " ' 26 January, 1950 to 13 May, 1962']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "presidents_term=[]\n",
    "\n",
    "for i in rfp_india_page.find_all('p',class_=\"\"):\n",
    "    presidents_term.append(i.text.split(\":\")[1])\n",
    "\n",
    "ind2remove=[1,3,5,7] ## Removing unwanted url from term of office\n",
    "\n",
    "for i in sorted(ind2remove,reverse=True):\n",
    "    del presidents_term[i]\n",
    "\n",
    "presidents_term\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "205b05eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>President Name</th>\n",
       "      <th>Term Of Office</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shri Ram Nath Kovind</td>\n",
       "      <td>25 July, 2017 to 25 July, 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shri Pranab Mukherjee</td>\n",
       "      <td>25 July, 2012 to 25 July, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Smt Pratibha Devisingh Patil</td>\n",
       "      <td>25 July, 2007 to 25 July, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DR. A.P.J. Abdul Kalam</td>\n",
       "      <td>25 July, 2002 to 25 July, 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shri K. R. Narayanan</td>\n",
       "      <td>25 July, 1997 to 25 July, 2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dr Shankar Dayal Sharma</td>\n",
       "      <td>25 July, 1992 to 25 July, 1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shri R Venkataraman</td>\n",
       "      <td>25 July, 1987 to 25 July, 1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Giani Zail Singh</td>\n",
       "      <td>25 July, 1982 to 25 July, 1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shri Neelam Sanjiva Reddy</td>\n",
       "      <td>25 July, 1977 to 25 July, 1982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dr. Fakhruddin Ali Ahmed</td>\n",
       "      <td>24 August, 1974 to 11 February, 1977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Shri Varahagiri Venkata Giri</td>\n",
       "      <td>3 May, 1969 to 20 July, 1969 and 24 August, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dr. Zakir Husain</td>\n",
       "      <td>13 May, 1967 to 3 May, 1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dr. Sarvepalli Radhakrishnan</td>\n",
       "      <td>13 May, 1962 to 13 May, 1967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dr. Rajendra Prasad</td>\n",
       "      <td>26 January, 1950 to 13 May, 1962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   President Name  \\\n",
       "0           Shri Ram Nath Kovind    \n",
       "1          Shri Pranab Mukherjee    \n",
       "2   Smt Pratibha Devisingh Patil    \n",
       "3         DR. A.P.J. Abdul Kalam    \n",
       "4           Shri K. R. Narayanan    \n",
       "5        Dr Shankar Dayal Sharma    \n",
       "6            Shri R Venkataraman    \n",
       "7               Giani Zail Singh    \n",
       "8      Shri Neelam Sanjiva Reddy    \n",
       "9       Dr. Fakhruddin Ali Ahmed    \n",
       "10  Shri Varahagiri Venkata Giri    \n",
       "11              Dr. Zakir Husain    \n",
       "12  Dr. Sarvepalli Radhakrishnan    \n",
       "13           Dr. Rajendra Prasad    \n",
       "\n",
       "                                       Term Of Office  \n",
       "0                     25 July, 2017 to 25 July, 2022   \n",
       "1                     25 July, 2012 to 25 July, 2017   \n",
       "2                     25 July, 2007 to 25 July, 2012   \n",
       "3                     25 July, 2002 to 25 July, 2007   \n",
       "4                     25 July, 1997 to 25 July, 2002   \n",
       "5                     25 July, 1992 to 25 July, 1997   \n",
       "6                     25 July, 1987 to 25 July, 1992   \n",
       "7                     25 July, 1982 to 25 July, 1987   \n",
       "8                     25 July, 1977 to 25 July, 1982   \n",
       "9                24 August, 1974 to 11 February, 1977  \n",
       "10   3 May, 1969 to 20 July, 1969 and 24 August, 1...  \n",
       "11                        13 May, 1967 to 3 May, 1969  \n",
       "12                       13 May, 1962 to 13 May, 1967  \n",
       "13                   26 January, 1950 to 13 May, 1962  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respected_former_presidents=pd.DataFrame({'President Name':presidents_name,'Term Of Office':presidents_term})\n",
    "respected_former_presidents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812b0967",
   "metadata": {},
   "source": [
    "# 5) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "\n",
    "a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "\n",
    "b) Top 10 ODI Batsmen along with the records of their team and rating.\n",
    "\n",
    "c) Top 10 ODI bowlers along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6385775d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "icc_batsmen=requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi')\n",
    "icc_team=requests.get('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')\n",
    "icc_bowler=requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling')\n",
    "\n",
    "icc_batsmen\n",
    "icc_team\n",
    "icc_bowler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "edd29dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "icc_batsmen=BeautifulSoup(icc_batsmen.content)\n",
    "icc_team=BeautifulSoup(icc_team.content)\n",
    "icc_bowler=BeautifulSoup(icc_bowler.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a4059c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match</th>\n",
       "      <th>Points</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>2,051</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>3,226</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>3,085</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>2,005</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>2,325</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21</td>\n",
       "      <td>2,111</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>27</td>\n",
       "      <td>2,639</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>29</td>\n",
       "      <td>2,658</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>38</td>\n",
       "      <td>2,621</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18</td>\n",
       "      <td>1,238</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Match  Points  Rating \n",
       "0     16   2,051     128\n",
       "1     27   3,226     119\n",
       "2     28   3,085     110\n",
       "3     19   2,005     106\n",
       "4     23   2,325     101\n",
       "5     21   2,111     101\n",
       "6     27   2,639      98\n",
       "7     29   2,658      92\n",
       "8     38   2,621      69\n",
       "9     18   1,238      69"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Top 10 ODI Team\n",
    "teamMatch=[]\n",
    "teamPoint=[]\n",
    "teamRating=[]\n",
    "\n",
    "for i in icc_team.find_all('td',class_=\"rankings-block__banner--matches\"):\n",
    "    teamMatch.append(i.text)\n",
    "\n",
    "for i in icc_team.find_all('td',class_=\"rankings-block__banner--points\"):\n",
    "    teamPoint.append(i.text)\n",
    "    \n",
    "for i in icc_team.find_all('td',class_=\"rankings-block__banner--rating u-text-right\"):\n",
    "    teamRating.append(i.text.strip())    \n",
    "    \n",
    "for i in icc_team.find_all('tr',class_=\"table-body\"):\n",
    "    teamMatch.append(i.text.replace('\\n',\" \").replace('SA',\"\").replace('WI',\"\").replace('SL',\"\").strip().split()[3])\n",
    "    \n",
    "for i in icc_team.find_all('tr',class_=\"table-body\"):\n",
    "    teamPoint.append(i.text.replace('\\n',\" \").replace('SA',\"\").replace('WI',\"\").replace('SL',\"\").strip().split()[4])\n",
    "        \n",
    "for i in icc_team.find_all('tr',class_=\"table-body\"):\n",
    "    teamRating.append(i.text.replace('\\n',\" \").replace('SA',\"\").replace('WI',\"\").replace('SL',\"\").strip().split()[5])  \n",
    "    \n",
    "\n",
    "\n",
    "TeamRating=pd.DataFrame({'Match ':teamMatch[0:10],'Points ':teamPoint[0:10],'Rating ':teamRating[0:10]})\n",
    "TeamRating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4b0109ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PAK</td>\n",
       "      <td>892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PAK</td>\n",
       "      <td>815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SA</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SA</td>\n",
       "      <td>784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IND</td>\n",
       "      <td>767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>IND</td>\n",
       "      <td>763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NZ</td>\n",
       "      <td>744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AUS</td>\n",
       "      <td>737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ENG</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AUS</td>\n",
       "      <td>715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Team Rating\n",
       "0  PAK    892\n",
       "1  PAK    815\n",
       "2   SA    789\n",
       "3   SA    784\n",
       "4  IND    767\n",
       "5  IND    763\n",
       "6   NZ    744\n",
       "7  AUS    737\n",
       "8  ENG    732\n",
       "9  AUS    715"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Top 10 ODI Batsmen\n",
    "batsmenRating=[]\n",
    "\n",
    "for i in icc_batsmen.find('div',class_=\"rankings-block__banner--rating\"):\n",
    "    batsmenRating.append(i.text)\n",
    "\n",
    "for i in icc_batsmen.find_all('td',class_=\"table-body__cell u-text-right rating\"):\n",
    "    batsmenRating.append(i.text)\n",
    "\n",
    "\n",
    "batsmenTeam=[]\n",
    "batsmenTeam.append('PAK')\n",
    "for i in icc_batsmen.find_all('span',class_=\"table-body__logo-text\"):\n",
    "    batsmenTeam.append(i.text)\n",
    "\n",
    "df=pd.DataFrame.from_dict({'Team':batsmenTeam[0:10],'Rating':batsmenRating[0:10]},orient='index')\n",
    "BatsMen=df.transpose()\n",
    "BatsMen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ebeef67b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NZ</td>\n",
       "      <td>697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IND</td>\n",
       "      <td>682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PAK</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AUS</td>\n",
       "      <td>679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFG</td>\n",
       "      <td>676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BAN</td>\n",
       "      <td>672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NZ</td>\n",
       "      <td>663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AFG</td>\n",
       "      <td>657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AFG</td>\n",
       "      <td>651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ENG</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Team  Rating \n",
       "0    NZ     697\n",
       "1   IND     682\n",
       "2   PAK     681\n",
       "3   AUS     679\n",
       "4   AFG     676\n",
       "5   BAN     672\n",
       "6    NZ     663\n",
       "7   AFG     657\n",
       "8   AFG     651\n",
       "9   ENG     640"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 10 bowlers\n",
    "bowler_Team=[]\n",
    "bowler_Rating=[]\n",
    "\n",
    "\n",
    "for i in icc_bowler.find_all('div',class_=\"rankings-block__banner--rating\"):\n",
    "    bowler_Rating.append(i.text)\n",
    "\n",
    "for i in icc_bowler.find_all('td',class_=\"table-body__cell rating\"):\n",
    "    bowler_Rating.append(i.text)\n",
    "\n",
    "for i in icc_bowler.find_all('div',class_=\"rankings-block__banner--nationality\"):\n",
    "    bowler_Team.append(i.text.strip())\n",
    "        \n",
    "\n",
    "for i in icc_bowler.find_all('span',class_=\"table-body__logo-text\"):\n",
    "    bowler_Team.append(i.text)\n",
    "       \n",
    "\n",
    "top_bowlers=pd.DataFrame({'Team ':bowler_Team[0:10],'Rating ':bowler_Rating[0:10]})\n",
    "top_bowlers                       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2830dca8",
   "metadata": {},
   "source": [
    "# 6) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "\n",
    "b) Top 10 women’s ODI Batting players along with the records of their team and rating.\n",
    "\n",
    "c) Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a89e703c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "women_team_url=requests.get('https://www.icc-cricket.com/rankings/womens/team-rankings/odi')\n",
    "women_top10_batting=requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi')\n",
    "women_top10_allRouder=requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder')\n",
    "\n",
    "women_team_url\n",
    "women_top10_batting\n",
    "women_top10_allRouder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "beecfad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "women_10_top_team=BeautifulSoup(women_team_url.content)\n",
    "women_10_top_batting=BeautifulSoup(women_top10_batting.content)\n",
    "women_10_top_allrounder=BeautifulSoup(women_top10_allRouder.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2af818b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AUS</td>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AUS</td>\n",
       "      <td>749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENG</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SA</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AUS</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AUS</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NZ</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ENG</td>\n",
       "      <td>667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SL</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>IND</td>\n",
       "      <td>649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Team Rating\n",
       "0  AUS    785\n",
       "1  AUS    749\n",
       "2  ENG    747\n",
       "3   SA    732\n",
       "4  AUS    710\n",
       "5  AUS    701\n",
       "6   NZ    681\n",
       "7  ENG    667\n",
       "8   SL    655\n",
       "9  IND    649"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Top 10 ODI Batsmen\n",
    "battingRating=[]\n",
    "\n",
    "for i in women_10_top_batting.find('div',class_=\"rankings-block__banner--rating\"):\n",
    "    battingRating.append(i.text)\n",
    "\n",
    "for i in women_10_top_batting.find_all('td',class_=\"table-body__cell u-text-right rating\"):\n",
    "    battingRating.append(i.text)\n",
    "\n",
    "\n",
    "battingTeam=[]\n",
    "battingTeam.append('AUS')\n",
    "for i in women_10_top_batting.find_all('span',class_=\"table-body__logo-text\"):\n",
    "    battingTeam.append(i.text)\n",
    "\n",
    "df=pd.DataFrame.from_dict({'Team':battingTeam[0:10],'Rating':battingRating[0:10]},orient='index')\n",
    "top_10_batting=df.transpose()\n",
    "top_10_batting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a307019f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match</th>\n",
       "      <th>Points</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>4,837</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>4,046</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>4,157</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>3,219</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>31</td>\n",
       "      <td>3,019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>2,768</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30</td>\n",
       "      <td>930</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11</td>\n",
       "      <td>1,962</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>495</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>351</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Match  Points  Rating \n",
       "0     33   4,837     167\n",
       "1     35   4,046     123\n",
       "2     32   4,157     119\n",
       "3     31   3,219     101\n",
       "4     30      31   3,019\n",
       "5     12   2,768      92\n",
       "6     30     930      78\n",
       "7     11   1,962      65\n",
       "8      8     495      45\n",
       "9      8     351      44"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Top 10 ODI Team\n",
    "top_teamMatch=[]\n",
    "top_teamPoint=[]\n",
    "top_teamRating=[]\n",
    "\n",
    "#for i in women_10_top_team.find_all('td',class_=\"rankings-block__banner--matches\"):\n",
    " #   top_teamMatch.append(i.text)\n",
    "\n",
    "for i in women_10_top_team.find_all('td',class_=\"rankings-block__banner--points\"):\n",
    "    top_teamPoint.append(i.text)\n",
    "    \n",
    "for i in women_10_top_team.find_all('td',class_=\"rankings-block__banner--rating u-text-right\"):\n",
    "    top_teamRating.append(i.text.strip())    \n",
    "    \n",
    "for i in women_10_top_team.find_all('tr',class_=\"table-body\"):\n",
    "    top_teamMatch.append(i.text.replace('\\n',\" \").replace('SA',\"\").replace('WI',\"\").replace('SL',\"\").replace('NZ',\"\").strip().split()[3])\n",
    "    \n",
    "for i in women_10_top_team.find_all('tr',class_=\"table-body\"):\n",
    "    top_teamPoint.append(i.text.replace('\\n',\" \").replace('SA',\"\").replace('WI',\"\").replace('SL',\"\").strip().split()[4])\n",
    "        \n",
    "for i in women_10_top_team.find_all('tr',class_=\"table-body\"):\n",
    "    top_teamRating.append(i.text.replace('\\n',\" \").replace('SA',\"\").replace('WI',\"\").replace('SL',\"\").strip().split()[5])  \n",
    "    \n",
    "\n",
    "TeamRating=pd.DataFrame({'Match ':top_teamMatch[0:10],'Points ':top_teamPoint[0:10],'Rating ':top_teamRating[0:10]})\n",
    "TeamRating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ec69e521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENG</td>\n",
       "      <td>379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AUS</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SA</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WI</td>\n",
       "      <td>339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NZ</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AUS</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>IND</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AUS</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ENG</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WI</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Team  Rating \n",
       "0   ENG     379\n",
       "1   AUS     374\n",
       "2    SA     349\n",
       "3    WI     339\n",
       "4    NZ     336\n",
       "5   AUS     270\n",
       "6   IND     252\n",
       "7   AUS     246\n",
       "8   ENG     220\n",
       "9    WI     207"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 10 bowlers\n",
    "top_allround_Team=[]\n",
    "top_allround_Rating=[]\n",
    "\n",
    "\n",
    "for i in women_10_top_allrounder.find_all('div',class_=\"rankings-block__banner--rating\"):\n",
    "    top_allround_Rating.append(i.text)\n",
    "\n",
    "for i in women_10_top_allrounder.find_all('td',class_=\"table-body__cell rating\"):\n",
    "    top_allround_Rating.append(i.text)\n",
    "\n",
    "for i in women_10_top_allrounder.find_all('div',class_=\"rankings-block__banner--nationality\"):\n",
    "    top_allround_Team.append(i.text.strip())\n",
    "        \n",
    "\n",
    "for i in women_10_top_allrounder.find_all('span',class_=\"table-body__logo-text\"):\n",
    "    top_allround_Team.append(i.text)\n",
    "       \n",
    "\n",
    "top_allround=pd.DataFrame({'Team ':top_allround_Team[0:10],'Rating ':top_allround_Rating[0:10]})\n",
    "top_allround                       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2311feda",
   "metadata": {},
   "source": [
    "# 7) Write a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world :\n",
    "        \n",
    "i) Headline\n",
    "\n",
    "ii) Time\n",
    "\n",
    "iii) News Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4bb8cc12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnbc_url=requests.get('https://www.cnbc.com/world/?region=world')\n",
    "cnbc_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "002f6979",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnbc_page=BeautifulSoup(cnbc_url.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f3f8f75b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#We are fetching all news under latest news section\n",
    "\n",
    "Headline=[]\n",
    "Time=[]\n",
    "News_Link=[]\n",
    "\n",
    "for i in cnbc_page.find_all('div',class_=\"LatestNews-headlineWrapper\"):\n",
    "    Headline.append(i.text.replace('2022',\"Ago\").split(\"Ago\")[1])\n",
    "    \n",
    "\n",
    "    \n",
    "for i in cnbc_page.find_all('time',class_=\"LatestNews-timestamp\"):\n",
    "    Time.append(i.text)\n",
    "\n",
    "for i in cnbc_page.find_all('a',class_=\"LatestNews-headline\"):\n",
    "    News_Link.append(i['href'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9c17e695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Time</th>\n",
       "      <th>News Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The best and worst places to live in the world...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/07/global-liveabi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>George Clooney had tequila, Ryan Reynolds gin....</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/07/george-clooney...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9 corporate leaders share their best hacks for...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/07/9-busy-people-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bethenny Frankel: The most successful people h...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/07/bethenny-frank...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 7 states with the least credit card debt</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/07/states-with-th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Albemarle beats estimates on lithium prices, C...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/07/lithium-is-key...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>These stocks are best positioned to weather a ...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/07/these-stocks-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Strong returns are hard to find in</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/07/strong-returns...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Some consumers are cutting back on restaurant ...</td>\n",
       "      <td>6 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/07/consumers-are-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Climate change is making some homes to costly ...</td>\n",
       "      <td>6 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/07/climate-change...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Why creating a horror movie haven on Netflix m...</td>\n",
       "      <td>7 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/07/netflix-may-be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Elon Musk challenges Twitter CEO Parag Agrawal...</td>\n",
       "      <td>21 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/06/elon-musk-chal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Large Indiana employers Eli Lilly and Cummins ...</td>\n",
       "      <td>22 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/08/06/eli-lilly-says...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Czech prince raises $300,000 in NFTs to restor...</td>\n",
       "      <td>August 6, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/08/06/27-year-old-bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>President Joe Biden tests negative for Covid-1...</td>\n",
       "      <td>August 6, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/08/06/president-joe-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Fed Governor Bowman sees 'similarly sized' int...</td>\n",
       "      <td>August 6, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/08/06/fed-governor-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>This 39-year-old makes $160K/month in passive ...</td>\n",
       "      <td>August 6, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/08/06/this-39-year-o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Most of Buffett’s portfolio is tied up in just...</td>\n",
       "      <td>August 6, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/08/06/most-of-warren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5 tips for cutting down on credit card costs a...</td>\n",
       "      <td>August 6, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/08/06/how-to-curb-cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>This 41-year-old left the U.S. for Bangkok and...</td>\n",
       "      <td>August 6, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/08/06/this-digital-n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>It's time to cash in on these attractive stock...</td>\n",
       "      <td>August 6, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/08/06/goldman-analys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Here's why getting fired from a job you hate c...</td>\n",
       "      <td>August 6, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/08/06/therapist-gett...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>'Stressed out' STD clinics struggle with surge...</td>\n",
       "      <td>August 6, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/08/06/monkeypox-std-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Want to build generational wealth? Avoid these...</td>\n",
       "      <td>August 6, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/08/06/building-gener...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>A.I.-powered drug hunters are nearing a pivota...</td>\n",
       "      <td>August 6, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/08/06/ai-powered-dru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>The</td>\n",
       "      <td>August 6, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/08/06/the-2022-stock...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Berkshire reports operating earnings surge, bu...</td>\n",
       "      <td>August 6, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/08/06/berkshire-hath...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Why the best states for business may be the wo...</td>\n",
       "      <td>August 6, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/08/06/state-worker-p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Higher prices, skimpier portions and apps — ho...</td>\n",
       "      <td>August 6, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/08/06/higher-prices-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>What to know before 'unretiring' if you're on ...</td>\n",
       "      <td>August 6, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/08/06/social-securit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Headline            Time  \\\n",
       "0   The best and worst places to live in the world...     2 Hours Ago   \n",
       "1   George Clooney had tequila, Ryan Reynolds gin....     4 Hours Ago   \n",
       "2   9 corporate leaders share their best hacks for...     4 Hours Ago   \n",
       "3   Bethenny Frankel: The most successful people h...     5 Hours Ago   \n",
       "4       The 7 states with the least credit card debt      5 Hours Ago   \n",
       "5   Albemarle beats estimates on lithium prices, C...     5 Hours Ago   \n",
       "6   These stocks are best positioned to weather a ...     5 Hours Ago   \n",
       "7                 Strong returns are hard to find in      5 Hours Ago   \n",
       "8   Some consumers are cutting back on restaurant ...     6 Hours Ago   \n",
       "9   Climate change is making some homes to costly ...     6 Hours Ago   \n",
       "10  Why creating a horror movie haven on Netflix m...     7 Hours Ago   \n",
       "11  Elon Musk challenges Twitter CEO Parag Agrawal...    21 Hours Ago   \n",
       "12  Large Indiana employers Eli Lilly and Cummins ...    22 Hours Ago   \n",
       "13  Czech prince raises $300,000 in NFTs to restor...  August 6, 2022   \n",
       "14  President Joe Biden tests negative for Covid-1...  August 6, 2022   \n",
       "15  Fed Governor Bowman sees 'similarly sized' int...  August 6, 2022   \n",
       "16  This 39-year-old makes $160K/month in passive ...  August 6, 2022   \n",
       "17  Most of Buffett’s portfolio is tied up in just...  August 6, 2022   \n",
       "18  5 tips for cutting down on credit card costs a...  August 6, 2022   \n",
       "19  This 41-year-old left the U.S. for Bangkok and...  August 6, 2022   \n",
       "20  It's time to cash in on these attractive stock...  August 6, 2022   \n",
       "21  Here's why getting fired from a job you hate c...  August 6, 2022   \n",
       "22  'Stressed out' STD clinics struggle with surge...  August 6, 2022   \n",
       "23  Want to build generational wealth? Avoid these...  August 6, 2022   \n",
       "24  A.I.-powered drug hunters are nearing a pivota...  August 6, 2022   \n",
       "25                                               The   August 6, 2022   \n",
       "26  Berkshire reports operating earnings surge, bu...  August 6, 2022   \n",
       "27  Why the best states for business may be the wo...  August 6, 2022   \n",
       "28  Higher prices, skimpier portions and apps — ho...  August 6, 2022   \n",
       "29  What to know before 'unretiring' if you're on ...  August 6, 2022   \n",
       "\n",
       "                                            News Link  \n",
       "0   https://www.cnbc.com/2022/08/07/global-liveabi...  \n",
       "1   https://www.cnbc.com/2022/08/07/george-clooney...  \n",
       "2   https://www.cnbc.com/2022/08/07/9-busy-people-...  \n",
       "3   https://www.cnbc.com/2022/08/07/bethenny-frank...  \n",
       "4   https://www.cnbc.com/2022/08/07/states-with-th...  \n",
       "5   https://www.cnbc.com/2022/08/07/lithium-is-key...  \n",
       "6   https://www.cnbc.com/2022/08/07/these-stocks-a...  \n",
       "7   https://www.cnbc.com/2022/08/07/strong-returns...  \n",
       "8   https://www.cnbc.com/2022/08/07/consumers-are-...  \n",
       "9   https://www.cnbc.com/2022/08/07/climate-change...  \n",
       "10  https://www.cnbc.com/2022/08/07/netflix-may-be...  \n",
       "11  https://www.cnbc.com/2022/08/06/elon-musk-chal...  \n",
       "12  https://www.cnbc.com/2022/08/06/eli-lilly-says...  \n",
       "13  https://www.cnbc.com/2022/08/06/27-year-old-bo...  \n",
       "14  https://www.cnbc.com/2022/08/06/president-joe-...  \n",
       "15  https://www.cnbc.com/2022/08/06/fed-governor-b...  \n",
       "16  https://www.cnbc.com/2022/08/06/this-39-year-o...  \n",
       "17  https://www.cnbc.com/2022/08/06/most-of-warren...  \n",
       "18  https://www.cnbc.com/2022/08/06/how-to-curb-cr...  \n",
       "19  https://www.cnbc.com/2022/08/06/this-digital-n...  \n",
       "20  https://www.cnbc.com/2022/08/06/goldman-analys...  \n",
       "21  https://www.cnbc.com/2022/08/06/therapist-gett...  \n",
       "22  https://www.cnbc.com/2022/08/06/monkeypox-std-...  \n",
       "23  https://www.cnbc.com/2022/08/06/building-gener...  \n",
       "24  https://www.cnbc.com/2022/08/06/ai-powered-dru...  \n",
       "25  https://www.cnbc.com/2022/08/06/the-2022-stock...  \n",
       "26  https://www.cnbc.com/2022/08/06/berkshire-hath...  \n",
       "27  https://www.cnbc.com/2022/08/06/state-worker-p...  \n",
       "28  https://www.cnbc.com/2022/08/06/higher-prices-...  \n",
       "29  https://www.cnbc.com/2022/08/06/social-securit...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Latest_news=pd.DataFrame({'Headline':Headline,'Time':Time,'News Link':News_Link})\n",
    "Latest_news"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b48dcd",
   "metadata": {},
   "source": [
    "# Q8 Write a python program to scrape the details of most downloaded articles from AI in last 90 days.\n",
    "https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\n",
    "\n",
    "Scrape below mentioned details :\n",
    "\n",
    "i) Paper Title\n",
    "\n",
    "ii) Authors\n",
    "\n",
    "iii) Published Date\n",
    "\n",
    "iv) Paper URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f385cfe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_url=requests.get('https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles')\n",
    "article_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e5a1fa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_page=BeautifulSoup(article_url.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c29922f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_title=[]\n",
    "authors=[]\n",
    "publishedDate=[]\n",
    "paperUrl=[]\n",
    "\n",
    "\n",
    "for i in article_page.find_all('h2',class_=\"sc-1qrq3sd-1 MKjKb sc-1nmom32-0 sc-1nmom32-1 hqhUYH ebTA-dR\"):\n",
    "    paper_title.append(i.text)\n",
    "\n",
    "for i in article_page.find_all('span',class_=\"sc-1w3fpd7-0 pgLAT\"):\n",
    "    authors.append(i.text)\n",
    "    \n",
    "for i in article_page.find_all('span',class_=\"sc-1thf9ly-2 bKddwo\"):\n",
    "    publishedDate.append(i.text)\n",
    "\n",
    "# find all the anchor tags with \"href\" \n",
    "# attribute starting with \"https://\"\n",
    "for i in article_page.find_all('a',attrs={'href': re.compile(\"^https://\")},class_=\"sc-5smygv-0 nrDZj\"):\n",
    "    paperUrl.append(i.get('href'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "114be3b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paper Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Published Date</th>\n",
       "      <th>Paper URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reward is enough</td>\n",
       "      <td>Silver, David, Singh, Satinder, Precup, Doina,...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Making sense of raw input</td>\n",
       "      <td>Evans, Richard, Bošnjak, Matko and 5 more</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Law and logic: A review from an argumentation ...</td>\n",
       "      <td>Prakken, Henry, Sartor, Giovanni</td>\n",
       "      <td>October 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Creativity and artificial intelligence</td>\n",
       "      <td>Boden, Margaret A.</td>\n",
       "      <td>August 1998</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Artificial cognition for social human–robot in...</td>\n",
       "      <td>Lemaignan, Séverin, Warnier, Mathieu and 3 more</td>\n",
       "      <td>June 2017</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Explanation in artificial intelligence: Insigh...</td>\n",
       "      <td>Miller, Tim</td>\n",
       "      <td>February 2019</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Making sense of sensory input</td>\n",
       "      <td>Evans, Richard, Hernández-Orallo, José and 3 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Conflict-based search for optimal multi-agent ...</td>\n",
       "      <td>Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...</td>\n",
       "      <td>February 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Between MDPs and semi-MDPs: A framework for te...</td>\n",
       "      <td>Sutton, Richard S., Precup, Doina, Singh, Sati...</td>\n",
       "      <td>August 1999</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Hanabi challenge: A new frontier for AI re...</td>\n",
       "      <td>Bard, Nolan, Foerster, Jakob N. and 13 more</td>\n",
       "      <td>March 2020</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Evaluating XAI: A comparison of rule-based and...</td>\n",
       "      <td>van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...</td>\n",
       "      <td>February 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Argumentation in artificial intelligence</td>\n",
       "      <td>Bench-Capon, T.J.M., Dunne, Paul E.</td>\n",
       "      <td>October 2007</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Algorithms for computing strategies in two-pla...</td>\n",
       "      <td>Bošanský, Branislav, Lisý, Viliam and 3 more</td>\n",
       "      <td>August 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Multiple object tracking: A literature review</td>\n",
       "      <td>Luo, Wenhan, Xing, Junliang and 4 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Selection of relevant features and examples in...</td>\n",
       "      <td>Blum, Avrim L., Langley, Pat</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A survey of inverse reinforcement learning: Ch...</td>\n",
       "      <td>Arora, Saurabh, Doshi, Prashant</td>\n",
       "      <td>August 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Explaining individual predictions when feature...</td>\n",
       "      <td>Aas, Kjersti, Jullum, Martin, Løland, Anders</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A review of possible effects of cognitive bias...</td>\n",
       "      <td>Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...</td>\n",
       "      <td>June 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Integrating social power into the decision-mak...</td>\n",
       "      <td>Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.</td>\n",
       "      <td>December 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>“That's (not) the output I expected!” On the r...</td>\n",
       "      <td>Riveiro, Maria, Thill, Serge</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Explaining black-box classifiers using post-ho...</td>\n",
       "      <td>Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...</td>\n",
       "      <td>May 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Algorithm runtime prediction: Methods &amp; evalua...</td>\n",
       "      <td>Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...</td>\n",
       "      <td>January 2014</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Wrappers for feature subset selection</td>\n",
       "      <td>Kohavi, Ron, John, George H.</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Commonsense visual sensemaking for autonomous ...</td>\n",
       "      <td>Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Quantum computation, quantum theory and AI</td>\n",
       "      <td>Ying, Mingsheng</td>\n",
       "      <td>February 2010</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Paper Title  \\\n",
       "0                                    Reward is enough   \n",
       "1                           Making sense of raw input   \n",
       "2   Law and logic: A review from an argumentation ...   \n",
       "3              Creativity and artificial intelligence   \n",
       "4   Artificial cognition for social human–robot in...   \n",
       "5   Explanation in artificial intelligence: Insigh...   \n",
       "6                       Making sense of sensory input   \n",
       "7   Conflict-based search for optimal multi-agent ...   \n",
       "8   Between MDPs and semi-MDPs: A framework for te...   \n",
       "9   The Hanabi challenge: A new frontier for AI re...   \n",
       "10  Evaluating XAI: A comparison of rule-based and...   \n",
       "11           Argumentation in artificial intelligence   \n",
       "12  Algorithms for computing strategies in two-pla...   \n",
       "13      Multiple object tracking: A literature review   \n",
       "14  Selection of relevant features and examples in...   \n",
       "15  A survey of inverse reinforcement learning: Ch...   \n",
       "16  Explaining individual predictions when feature...   \n",
       "17  A review of possible effects of cognitive bias...   \n",
       "18  Integrating social power into the decision-mak...   \n",
       "19  “That's (not) the output I expected!” On the r...   \n",
       "20  Explaining black-box classifiers using post-ho...   \n",
       "21  Algorithm runtime prediction: Methods & evalua...   \n",
       "22              Wrappers for feature subset selection   \n",
       "23  Commonsense visual sensemaking for autonomous ...   \n",
       "24         Quantum computation, quantum theory and AI   \n",
       "\n",
       "                                              Authors  Published Date  \\\n",
       "0   Silver, David, Singh, Satinder, Precup, Doina,...    October 2021   \n",
       "1           Evans, Richard, Bošnjak, Matko and 5 more    October 2021   \n",
       "2                   Prakken, Henry, Sartor, Giovanni     October 2015   \n",
       "3                                 Boden, Margaret A.      August 1998   \n",
       "4     Lemaignan, Séverin, Warnier, Mathieu and 3 more       June 2017   \n",
       "5                                        Miller, Tim    February 2019   \n",
       "6   Evans, Richard, Hernández-Orallo, José and 3 more      April 2021   \n",
       "7   Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...   February 2015   \n",
       "8   Sutton, Richard S., Precup, Doina, Singh, Sati...     August 1999   \n",
       "9         Bard, Nolan, Foerster, Jakob N. and 13 more      March 2020   \n",
       "10  van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...   February 2021   \n",
       "11               Bench-Capon, T.J.M., Dunne, Paul E.     October 2007   \n",
       "12       Bošanský, Branislav, Lisý, Viliam and 3 more     August 2016   \n",
       "13             Luo, Wenhan, Xing, Junliang and 4 more      April 2021   \n",
       "14                      Blum, Avrim L., Langley, Pat    December 1997   \n",
       "15                   Arora, Saurabh, Doshi, Prashant      August 2021   \n",
       "16      Aas, Kjersti, Jullum, Martin, Løland, Anders   September 2021   \n",
       "17  Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...       June 2021   \n",
       "18    Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.    December 2016   \n",
       "19                      Riveiro, Maria, Thill, Serge   September 2021   \n",
       "20  Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...        May 2021   \n",
       "21  Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...    January 2014   \n",
       "22                      Kohavi, Ron, John, George H.    December 1997   \n",
       "23  Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...    October 2021   \n",
       "24                                   Ying, Mingsheng    February 2010   \n",
       "\n",
       "                                            Paper URL  \n",
       "0   https://www.sciencedirect.com/science/article/...  \n",
       "1   https://www.sciencedirect.com/science/article/...  \n",
       "2   https://www.sciencedirect.com/science/article/...  \n",
       "3   https://www.sciencedirect.com/science/article/...  \n",
       "4   https://www.sciencedirect.com/science/article/...  \n",
       "5   https://www.sciencedirect.com/science/article/...  \n",
       "6   https://www.sciencedirect.com/science/article/...  \n",
       "7   https://www.sciencedirect.com/science/article/...  \n",
       "8   https://www.sciencedirect.com/science/article/...  \n",
       "9   https://www.sciencedirect.com/science/article/...  \n",
       "10  https://www.sciencedirect.com/science/article/...  \n",
       "11  https://www.sciencedirect.com/science/article/...  \n",
       "12  https://www.sciencedirect.com/science/article/...  \n",
       "13  https://www.sciencedirect.com/science/article/...  \n",
       "14  https://www.sciencedirect.com/science/article/...  \n",
       "15  https://www.sciencedirect.com/science/article/...  \n",
       "16  https://www.sciencedirect.com/science/article/...  \n",
       "17  https://www.sciencedirect.com/science/article/...  \n",
       "18  https://www.sciencedirect.com/science/article/...  \n",
       "19  https://www.sciencedirect.com/science/article/...  \n",
       "20  https://www.sciencedirect.com/science/article/...  \n",
       "21  https://www.sciencedirect.com/science/article/...  \n",
       "22  https://www.sciencedirect.com/science/article/...  \n",
       "23  https://www.sciencedirect.com/science/article/...  \n",
       "24  https://www.sciencedirect.com/science/article/...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ai_Aritcle=pd.DataFrame({'Paper Title':paper_title,'Authors':authors,'Published Date':publishedDate,'Paper URL':paperUrl})\n",
    "Ai_Aritcle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a6aa1f",
   "metadata": {},
   "source": [
    "# 9) Write a python program to scrape mentioned details from dineout.co.in :\n",
    "    \n",
    "i) Restaurant name\n",
    "ii) Cuisine\n",
    "iii) Location\n",
    "iv) Ratings\n",
    "v) Image URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "819ffe46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dineout_url=requests.get('https://www.dineout.co.in/delhi-restaurants/buffet-special')\n",
    "dineout_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "48c7175e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dineout_page=BeautifulSoup(dineout_url.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d66bb3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "RestaurantName=[]\n",
    "Cuisine=[]\n",
    "Location=[]\n",
    "Ratings=[]\n",
    "ImageURL=[]\n",
    "\n",
    "for i in dineout_page.find_all('div',class_=\"restnt-info cursor\"):\n",
    "    RestaurantName.append(i.text)\n",
    "\n",
    "for i in dineout_page.find_all('span',class_=\"double-line-ellipsis\"):\n",
    "    Cuisine.append(i.text.split(\"|\")[1])\n",
    "\n",
    "for i in dineout_page.find_all('div',class_=\"restnt-loc ellipsis\"):\n",
    "    Location.append(i.text)\n",
    "\n",
    "for i in dineout_page.find_all('div',class_=\"restnt-rating rating-4\"):\n",
    "    Ratings.append(i.text)\n",
    "\n",
    "for i in dineout_page.find_all('img',class_=\"no-img\"):\n",
    "    ImageURL.append(i['data-src'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "429d5b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant name</th>\n",
       "      <th>Cuisine</th>\n",
       "      <th>Location</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Image URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Castle BarbequeConnaught Place, Central Delhi</td>\n",
       "      <td>Chinese, North Indian</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jungle Jamboree3CS Mall,Lajpat Nagar - 3, Sout...</td>\n",
       "      <td>North Indian, Asian, Italian</td>\n",
       "      <td>3CS Mall,Lajpat Nagar - 3, South Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Castle BarbequePacific Mall,Tagore Garden, Wes...</td>\n",
       "      <td>Chinese, North Indian</td>\n",
       "      <td>Pacific Mall,Tagore Garden, West Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cafe KnoshThe Leela Ambience Convention Hotel,...</td>\n",
       "      <td>Italian, Continental</td>\n",
       "      <td>The Leela Ambience Convention Hotel,Shahdara, ...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Barbeque CompanyGardens Galleria,Sector 38...</td>\n",
       "      <td>North Indian, Chinese</td>\n",
       "      <td>Gardens Galleria,Sector 38A, Noida</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>India GrillHilton Garden Inn,Saket, South Delhi</td>\n",
       "      <td>North Indian, Italian</td>\n",
       "      <td>Hilton Garden Inn,Saket, South Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Delhi BarbequeTaurus Sarovar Portico,Mahipalpu...</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>Taurus Sarovar Portico,Mahipalpur, South Delhi</td>\n",
       "      <td>3.7</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Monarch - Bar Be Que VillageIndirapuram Ha...</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>Indirapuram Habitat Centre,Indirapuram, Ghaziabad</td>\n",
       "      <td>3.8</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Indian Grill RoomSuncity Business Tower,Golf C...</td>\n",
       "      <td>North Indian, Mughlai</td>\n",
       "      <td>Suncity Business Tower,Golf Course Road, Gurgaon</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Restaurant name  \\\n",
       "0      Castle BarbequeConnaught Place, Central Delhi   \n",
       "1  Jungle Jamboree3CS Mall,Lajpat Nagar - 3, Sout...   \n",
       "2  Castle BarbequePacific Mall,Tagore Garden, Wes...   \n",
       "3  Cafe KnoshThe Leela Ambience Convention Hotel,...   \n",
       "4  The Barbeque CompanyGardens Galleria,Sector 38...   \n",
       "5    India GrillHilton Garden Inn,Saket, South Delhi   \n",
       "6  Delhi BarbequeTaurus Sarovar Portico,Mahipalpu...   \n",
       "7  The Monarch - Bar Be Que VillageIndirapuram Ha...   \n",
       "8  Indian Grill RoomSuncity Business Tower,Golf C...   \n",
       "\n",
       "                         Cuisine  \\\n",
       "0          Chinese, North Indian   \n",
       "1   North Indian, Asian, Italian   \n",
       "2          Chinese, North Indian   \n",
       "3           Italian, Continental   \n",
       "4          North Indian, Chinese   \n",
       "5          North Indian, Italian   \n",
       "6                   North Indian   \n",
       "7                   North Indian   \n",
       "8          North Indian, Mughlai   \n",
       "\n",
       "                                            Location Ratings  \\\n",
       "0                     Connaught Place, Central Delhi     4.1   \n",
       "1             3CS Mall,Lajpat Nagar - 3, South Delhi     3.9   \n",
       "2             Pacific Mall,Tagore Garden, West Delhi     3.9   \n",
       "3  The Leela Ambience Convention Hotel,Shahdara, ...     4.3   \n",
       "4                 Gardens Galleria,Sector 38A, Noida       4   \n",
       "5               Hilton Garden Inn,Saket, South Delhi     3.9   \n",
       "6     Taurus Sarovar Portico,Mahipalpur, South Delhi     3.7   \n",
       "7  Indirapuram Habitat Centre,Indirapuram, Ghaziabad     3.8   \n",
       "8   Suncity Business Tower,Golf Course Road, Gurgaon     4.3   \n",
       "\n",
       "                                           Image URL  \n",
       "0  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "1  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "2  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "3  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "4  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "5  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "6  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "7  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "8  https://im1.dineout.co.in/images/uploads/resta...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dineout=pd.DataFrame({'Restaurant name':RestaurantName,'Cuisine':Cuisine,'Location':Location,'Ratings':Ratings,'Image URL':ImageURL})\n",
    "Dineout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f9760f",
   "metadata": {},
   "source": [
    "# 10) Write a python program to scrape the details of top publications from Google Scholar from\n",
    "https://scholar.google.com/citations?view_op=top_venues&hl=en\n",
    "\n",
    "i) Rank\n",
    "ii) Publication\n",
    "iii) h5-index\n",
    "iv) h5-median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f3ff6162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GoogleScholar_url=requests.get('https://scholar.google.com/citations?view_op=top_venues&hl=en')\n",
    "GoogleScholar_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "068adbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "GoogleScholar_Page=BeautifulSoup(GoogleScholar_url.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5c8e1eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank=[]\n",
    "Publication=[]\n",
    "h5_index=[]\n",
    "h5_median=[]\n",
    "\n",
    "for i in GoogleScholar_Page.find_all('td',class_=\"gsc_mvt_p\"):\n",
    "    rank.append(i.text)\n",
    "\n",
    "for i in GoogleScholar_Page.find_all('td',class_=\"gsc_mvt_t\"):\n",
    "    Publication.append(i.text)\n",
    "\n",
    "for i in GoogleScholar_Page.find_all('a',class_=\"gs_ibl gsc_mp_anchor\"):\n",
    "    h5_index.append(i.text)\n",
    "\n",
    "for i in GoogleScholar_Page.find_all('span',class_=\"gs_ibl gsc_mp_anchor\"):\n",
    "    h5_median.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f8441006",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Publication</th>\n",
       "      <th>h5-index</th>\n",
       "      <th>h5-median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>Nature</td>\n",
       "      <td>444</td>\n",
       "      <td>667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>The New England Journal of Medicine</td>\n",
       "      <td>432</td>\n",
       "      <td>780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>Science</td>\n",
       "      <td>401</td>\n",
       "      <td>614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>IEEE/CVF Conference on Computer Vision and Pat...</td>\n",
       "      <td>389</td>\n",
       "      <td>627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>The Lancet</td>\n",
       "      <td>354</td>\n",
       "      <td>635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96.</td>\n",
       "      <td>Journal of Business Research</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97.</td>\n",
       "      <td>Molecular Cancer</td>\n",
       "      <td>145</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98.</td>\n",
       "      <td>Sensors</td>\n",
       "      <td>145</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99.</td>\n",
       "      <td>Nature Climate Change</td>\n",
       "      <td>144</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100.</td>\n",
       "      <td>IEEE Internet of Things Journal</td>\n",
       "      <td>144</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rank                                        Publication h5-index h5-median\n",
       "0     1.                                             Nature      444       667\n",
       "1     2.                The New England Journal of Medicine      432       780\n",
       "2     3.                                            Science      401       614\n",
       "3     4.  IEEE/CVF Conference on Computer Vision and Pat...      389       627\n",
       "4     5.                                         The Lancet      354       635\n",
       "..   ...                                                ...      ...       ...\n",
       "95   96.                       Journal of Business Research      145       233\n",
       "96   97.                                   Molecular Cancer      145       209\n",
       "97   98.                                            Sensors      145       201\n",
       "98   99.                              Nature Climate Change      144       228\n",
       "99  100.                    IEEE Internet of Things Journal      144       212\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Google_Scholar=pd.DataFrame({'Rank':rank,'Publication':Publication,'h5-index':h5_index,'h5-median':h5_median})\n",
    "Google_Scholar"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
